{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "# PyTorch\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "# Laplace\n",
    "from laplace import Laplace\n",
    "from laplace.curvature import AsdlEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Importing our custom module(s)\n",
    "import losses\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{hours} hrs. {minutes} mins. {seconds} secs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'l2-zero'\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_diagEF'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'runtime', 'train_log_marglik', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df['train_sec/epoch'].sum(), temp_df.train_log_marglik.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=100_random_state=1001</td>\n",
       "      <td>100</td>\n",
       "      <td>1001</td>\n",
       "      <td>7008.146201</td>\n",
       "      <td>-263.259644</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>1.057087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=100_random_state=2001</td>\n",
       "      <td>100</td>\n",
       "      <td>2001</td>\n",
       "      <td>7000.924933</td>\n",
       "      <td>-242.931412</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>1.055820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=100_random_state=3001</td>\n",
       "      <td>100</td>\n",
       "      <td>3001</td>\n",
       "      <td>6952.630825</td>\n",
       "      <td>-223.579773</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>1.024537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=1000_random_state=1001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4952.520816</td>\n",
       "      <td>-404.404633</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.442697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=1000_random_state=2001</td>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4963.107343</td>\n",
       "      <td>-424.987091</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>0.466042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=1000_random_state=3001</td>\n",
       "      <td>1000</td>\n",
       "      <td>3001</td>\n",
       "      <td>5867.403218</td>\n",
       "      <td>-388.481537</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.480824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=10000_random_state=1001</td>\n",
       "      <td>10000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4168.477561</td>\n",
       "      <td>-1875.979858</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.203911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=10000_random_state=2001</td>\n",
       "      <td>10000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4130.892845</td>\n",
       "      <td>-2439.328857</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.211288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=10000_random_state=3001</td>\n",
       "      <td>10000</td>\n",
       "      <td>3001</td>\n",
       "      <td>4162.006493</td>\n",
       "      <td>-2173.709717</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.191490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=50000_random_state=1001</td>\n",
       "      <td>50000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4176.966407</td>\n",
       "      <td>-146591.953125</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.116327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=50000_random_state=2001</td>\n",
       "      <td>50000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4114.107446</td>\n",
       "      <td>-170956.500000</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.114583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=50000_random_state=3001</td>\n",
       "      <td>50000</td>\n",
       "      <td>3001</td>\n",
       "      <td>4109.987952</td>\n",
       "      <td>-149952.875000</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.115110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                   model_name      n  \\\n",
       "12   l2-zero    l2-zero_lr_0=0.01_n=100_random_state=1001    100   \n",
       "13   l2-zero    l2-zero_lr_0=0.01_n=100_random_state=2001    100   \n",
       "14   l2-zero    l2-zero_lr_0=0.01_n=100_random_state=3001    100   \n",
       "15   l2-zero   l2-zero_lr_0=0.01_n=1000_random_state=1001   1000   \n",
       "16   l2-zero   l2-zero_lr_0=0.01_n=1000_random_state=2001   1000   \n",
       "17   l2-zero   l2-zero_lr_0=0.01_n=1000_random_state=3001   1000   \n",
       "18   l2-zero  l2-zero_lr_0=0.01_n=10000_random_state=1001  10000   \n",
       "19   l2-zero  l2-zero_lr_0=0.01_n=10000_random_state=2001  10000   \n",
       "20   l2-zero  l2-zero_lr_0=0.01_n=10000_random_state=3001  10000   \n",
       "21   l2-zero  l2-zero_lr_0=0.01_n=50000_random_state=1001  50000   \n",
       "22   l2-zero  l2-zero_lr_0=0.01_n=50000_random_state=2001  50000   \n",
       "23   l2-zero  l2-zero_lr_0=0.01_n=50000_random_state=3001  50000   \n",
       "\n",
       "    random_state      runtime  train_log_marglik  test_acc  test_nll  \n",
       "12          1001  7008.146201        -263.259644    0.6745  1.057087  \n",
       "13          2001  7000.924933        -242.931412    0.6659  1.055820  \n",
       "14          3001  6952.630825        -223.579773    0.6846  1.024537  \n",
       "15          1001  4952.520816        -404.404633    0.8877  0.442697  \n",
       "16          2001  4963.107343        -424.987091    0.8809  0.466042  \n",
       "17          3001  5867.403218        -388.481537    0.8779  0.480824  \n",
       "18          1001  4168.477561       -1875.979858    0.9509  0.203911  \n",
       "19          2001  4130.892845       -2439.328857    0.9506  0.211288  \n",
       "20          3001  4162.006493       -2173.709717    0.9517  0.191490  \n",
       "21          1001  4176.966407     -146591.953125    0.9696  0.116327  \n",
       "22          2001  4114.107446     -170956.500000    0.9695  0.114583  \n",
       "23          3001  4109.987952     -149952.875000    0.9691  0.115110  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_indices = retrained_df.groupby(['criterion', 'n', 'random_state'])['train_log_marglik'].idxmax()\n",
    "retrained_df = retrained_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>100</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=100_random_state=1001, l2...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(7008.146201372147, 7000.924933433533, 6952.63...</td>\n",
       "      <td>(-263.2596435546875, -242.9314117431641, -223....</td>\n",
       "      <td>(0.6744999885559082, 0.6658999919891357, 0.684...</td>\n",
       "      <td>(1.0570869313240052, 1.0558203800201416, 1.024...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>1.045815</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>1.024537</td>\n",
       "      <td>1.057087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1000</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=1000_random_state=1001, l...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(4952.520815849304, 4963.107343196869, 5867.40...</td>\n",
       "      <td>(-404.4046325683594, -424.9870910644531, -388....</td>\n",
       "      <td>(0.887700080871582, 0.8809000849723816, 0.8779...</td>\n",
       "      <td>(0.4426965748786928, 0.466041524219513, 0.4808...</td>\n",
       "      <td>0.882167</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.463187</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.442697</td>\n",
       "      <td>0.480824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>10000</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=10000_random_state=1001, ...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(4168.477560520172, 4130.892844676971, 4162.00...</td>\n",
       "      <td>(-1875.9798583984373, -2439.328857421875, -217...</td>\n",
       "      <td>(0.9509000778198242, 0.95059996843338, 0.95170...</td>\n",
       "      <td>(0.2039114191532135, 0.21128786611557, 0.19148...</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.202230</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.191490</td>\n",
       "      <td>0.211288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>50000</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=50000_random_state=1001, ...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(4176.966406583786, 4114.107445716858, 4109.98...</td>\n",
       "      <td>(-146591.953125, -170956.5, -149952.875)</td>\n",
       "      <td>(0.9696000218391418, 0.9695000648498536, 0.969...</td>\n",
       "      <td>(0.1163268289327621, 0.1145831343889236, 0.115...</td>\n",
       "      <td>0.969400</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.116327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n                                         model_name  \\\n",
       "0   l2-zero    100  (l2-zero_lr_0=0.01_n=100_random_state=1001, l2...   \n",
       "1   l2-zero   1000  (l2-zero_lr_0=0.01_n=1000_random_state=1001, l...   \n",
       "2   l2-zero  10000  (l2-zero_lr_0=0.01_n=10000_random_state=1001, ...   \n",
       "3   l2-zero  50000  (l2-zero_lr_0=0.01_n=50000_random_state=1001, ...   \n",
       "\n",
       "         random_state                                            runtime  \\\n",
       "0  (1001, 2001, 3001)  (7008.146201372147, 7000.924933433533, 6952.63...   \n",
       "1  (1001, 2001, 3001)  (4952.520815849304, 4963.107343196869, 5867.40...   \n",
       "2  (1001, 2001, 3001)  (4168.477560520172, 4130.892844676971, 4162.00...   \n",
       "3  (1001, 2001, 3001)  (4176.966406583786, 4114.107445716858, 4109.98...   \n",
       "\n",
       "                                   train_log_marglik  \\\n",
       "0  (-263.2596435546875, -242.9314117431641, -223....   \n",
       "1  (-404.4046325683594, -424.9870910644531, -388....   \n",
       "2  (-1875.9798583984373, -2439.328857421875, -217...   \n",
       "3           (-146591.953125, -170956.5, -149952.875)   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.6744999885559082, 0.6658999919891357, 0.684...   \n",
       "1  (0.887700080871582, 0.8809000849723816, 0.8779...   \n",
       "2  (0.9509000778198242, 0.95059996843338, 0.95170...   \n",
       "3  (0.9696000218391418, 0.9695000648498536, 0.969...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (1.0570869313240052, 1.0558203800201416, 1.024...       0.675000   \n",
       "1  (0.4426965748786928, 0.466041524219513, 0.4808...       0.882167   \n",
       "2  (0.2039114191532135, 0.21128786611557, 0.19148...       0.951067   \n",
       "3  (0.1163268289327621, 0.1145831343889236, 0.115...       0.969400   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.007642        0.6659        0.6846       1.045815      0.015054   \n",
       "1      0.004100        0.8779        0.8877       0.463187      0.015696   \n",
       "2      0.000464        0.9506        0.9517       0.202230      0.008170   \n",
       "3      0.000216        0.9691        0.9696       0.115340      0.000730   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      1.024537      1.057087  \n",
       "1      0.442697      0.480824  \n",
       "2      0.191490      0.211288  \n",
       "3      0.114583      0.116327  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>100</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>0.6846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.882167</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.8877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.969400</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0   l2-zero    100       0.675000        0.6659        0.6846\n",
       "1   l2-zero   1000       0.882167        0.8779        0.8877\n",
       "2   l2-zero  10000       0.951067        0.9506        0.9517\n",
       "3   l2-zero  50000       0.969400        0.9691        0.9696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>100</td>\n",
       "      <td>1.045815</td>\n",
       "      <td>1.024537</td>\n",
       "      <td>1.057087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.463187</td>\n",
       "      <td>0.442697</td>\n",
       "      <td>0.480824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.202230</td>\n",
       "      <td>0.191490</td>\n",
       "      <td>0.211288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.116327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0   l2-zero    100       1.045815      1.024537      1.057087\n",
       "1   l2-zero   1000       0.463187      0.442697      0.480824\n",
       "2   l2-zero  10000       0.202230      0.191490      0.211288\n",
       "3   l2-zero  50000       0.115340      0.114583      0.116327"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'l2-sp'\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_diagEF'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'runtime', 'train_log_marglik', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df['train_sec/epoch'].sum(), temp_df.train_log_marglik.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime (sec.): 1.0 hrs. 9.0 mins. 54.06496077775955 secs.\n",
      "Total time (sec.): 4.0 hrs. 39.0 mins. 36.25984311103821 secs.\n"
     ]
    }
   ],
   "source": [
    "condition = (retrained_df.n==50000)&(retrained_df.criterion=='l2-sp')&(retrained_df.random_state==1001)\n",
    "temp_df = retrained_df.loc[condition]\n",
    "total_time = temp_df.runtime.sum()\n",
    "average_time = total_time/temp_df.shape[0]\n",
    "print(f'Average runtime (sec.): {format_time(average_time)}')\n",
    "print(f'Total time (sec.): {format_time(total_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=100_random_state=1001</td>\n",
       "      <td>100</td>\n",
       "      <td>1001</td>\n",
       "      <td>7771.870146</td>\n",
       "      <td>-230.257370</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>2.302569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=100_random_state=2001</td>\n",
       "      <td>100</td>\n",
       "      <td>2001</td>\n",
       "      <td>7320.807987</td>\n",
       "      <td>-230.257629</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>2.302573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=100_random_state=3001</td>\n",
       "      <td>100</td>\n",
       "      <td>3001</td>\n",
       "      <td>7323.553846</td>\n",
       "      <td>-230.256729</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>2.302560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=1000_random_state=1001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001</td>\n",
       "      <td>5009.549274</td>\n",
       "      <td>-1781.315430</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>1.193988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=1000_random_state=2001</td>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4991.712644</td>\n",
       "      <td>-1749.486816</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>1.171732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=1000_random_state=3001</td>\n",
       "      <td>1000</td>\n",
       "      <td>3001</td>\n",
       "      <td>5644.311024</td>\n",
       "      <td>-1749.390137</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>1.172170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=10000_random_state=1001</td>\n",
       "      <td>10000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4249.529740</td>\n",
       "      <td>-11346.691406</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.777652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=10000_random_state=2001</td>\n",
       "      <td>10000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4185.410539</td>\n",
       "      <td>-11566.898438</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.781921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=10000_random_state=3001</td>\n",
       "      <td>10000</td>\n",
       "      <td>3001</td>\n",
       "      <td>4257.878783</td>\n",
       "      <td>-11260.216797</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=50000_random_state=1001</td>\n",
       "      <td>50000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4476.865883</td>\n",
       "      <td>-31109.111328</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.186945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=50000_random_state=2001</td>\n",
       "      <td>50000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4307.140011</td>\n",
       "      <td>-29757.199219</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.173801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=50000_random_state=3001</td>\n",
       "      <td>50000</td>\n",
       "      <td>3001</td>\n",
       "      <td>4162.760472</td>\n",
       "      <td>-30299.488281</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.174778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                 model_name      n  random_state  \\\n",
       "12     l2-sp    l2-sp_lr_0=0.01_n=100_random_state=1001    100          1001   \n",
       "1      l2-sp     l2-sp_lr_0=0.1_n=100_random_state=2001    100          2001   \n",
       "14     l2-sp    l2-sp_lr_0=0.01_n=100_random_state=3001    100          3001   \n",
       "3      l2-sp    l2-sp_lr_0=0.1_n=1000_random_state=1001   1000          1001   \n",
       "16     l2-sp   l2-sp_lr_0=0.01_n=1000_random_state=2001   1000          2001   \n",
       "17     l2-sp   l2-sp_lr_0=0.01_n=1000_random_state=3001   1000          3001   \n",
       "18     l2-sp  l2-sp_lr_0=0.01_n=10000_random_state=1001  10000          1001   \n",
       "19     l2-sp  l2-sp_lr_0=0.01_n=10000_random_state=2001  10000          2001   \n",
       "20     l2-sp  l2-sp_lr_0=0.01_n=10000_random_state=3001  10000          3001   \n",
       "9      l2-sp   l2-sp_lr_0=0.1_n=50000_random_state=1001  50000          1001   \n",
       "10     l2-sp   l2-sp_lr_0=0.1_n=50000_random_state=2001  50000          2001   \n",
       "11     l2-sp   l2-sp_lr_0=0.1_n=50000_random_state=3001  50000          3001   \n",
       "\n",
       "        runtime  train_log_marglik  test_acc  test_nll  \n",
       "12  7771.870146        -230.257370    0.3405  2.302569  \n",
       "1   7320.807987        -230.257629    0.3673  2.302573  \n",
       "14  7323.553846        -230.256729    0.3423  2.302560  \n",
       "3   5009.549274       -1781.315430    0.7220  1.193988  \n",
       "16  4991.712644       -1749.486816    0.7241  1.171732  \n",
       "17  5644.311024       -1749.390137    0.7134  1.172170  \n",
       "18  4249.529740      -11346.691406    0.7628  0.777652  \n",
       "19  4185.410539      -11566.898438    0.7650  0.781921  \n",
       "20  4257.878783      -11260.216797    0.7645  0.784060  \n",
       "9   4476.865883      -31109.111328    0.9372  0.186945  \n",
       "10  4307.140011      -29757.199219    0.9432  0.173801  \n",
       "11  4162.760472      -30299.488281    0.9438  0.174778  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_indices = retrained_df.groupby(['criterion', 'n', 'random_state'])['train_log_marglik'].idxmax()\n",
    "retrained_df = retrained_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>100</td>\n",
       "      <td>(l2-sp_lr_0=0.01_n=100_random_state=1001, l2-s...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(7771.870146036148, 7320.807987213135, 7323.55...</td>\n",
       "      <td>(-230.2573699951172, -230.25762939453125, -230...</td>\n",
       "      <td>(0.3404999673366546, 0.3673000037670135, 0.342...</td>\n",
       "      <td>(2.302569054031372, 2.3025725662231444, 2.3025...</td>\n",
       "      <td>0.350033</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>2.302567</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.302560</td>\n",
       "      <td>2.302573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1000</td>\n",
       "      <td>(l2-sp_lr_0=0.1_n=1000_random_state=1001, l2-s...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(5009.5492742061615, 4991.712643861771, 5644.3...</td>\n",
       "      <td>(-1781.3154296875, -1749.48681640625, -1749.39...</td>\n",
       "      <td>(0.722000002861023, 0.7240999937057495, 0.7134...</td>\n",
       "      <td>(1.1939880359649662, 1.1717322761535645, 1.172...</td>\n",
       "      <td>0.719833</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>1.179297</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>1.171732</td>\n",
       "      <td>1.193988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>10000</td>\n",
       "      <td>(l2-sp_lr_0=0.01_n=10000_random_state=1001, l2...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(4249.529740095139, 4185.4105389118195, 4257.8...</td>\n",
       "      <td>(-11346.69140625, -11566.8984375, -11260.21679...</td>\n",
       "      <td>(0.7628000378608704, 0.7649999856948853, 0.764...</td>\n",
       "      <td>(0.7776520441055297, 0.7819208739280702, 0.784...</td>\n",
       "      <td>0.764100</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.781211</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.777652</td>\n",
       "      <td>0.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>50000</td>\n",
       "      <td>(l2-sp_lr_0=0.1_n=50000_random_state=1001, l2-...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(4476.865883111954, 4307.140010595322, 4162.76...</td>\n",
       "      <td>(-31109.111328125, -29757.19921875, -30299.488...</td>\n",
       "      <td>(0.9372000694274902, 0.9431999921798706, 0.943...</td>\n",
       "      <td>(0.1869448745250701, 0.1738006152153015, 0.174...</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.178508</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.173801</td>\n",
       "      <td>0.186945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n                                         model_name  \\\n",
       "0     l2-sp    100  (l2-sp_lr_0=0.01_n=100_random_state=1001, l2-s...   \n",
       "1     l2-sp   1000  (l2-sp_lr_0=0.1_n=1000_random_state=1001, l2-s...   \n",
       "2     l2-sp  10000  (l2-sp_lr_0=0.01_n=10000_random_state=1001, l2...   \n",
       "3     l2-sp  50000  (l2-sp_lr_0=0.1_n=50000_random_state=1001, l2-...   \n",
       "\n",
       "         random_state                                            runtime  \\\n",
       "0  (1001, 2001, 3001)  (7771.870146036148, 7320.807987213135, 7323.55...   \n",
       "1  (1001, 2001, 3001)  (5009.5492742061615, 4991.712643861771, 5644.3...   \n",
       "2  (1001, 2001, 3001)  (4249.529740095139, 4185.4105389118195, 4257.8...   \n",
       "3  (1001, 2001, 3001)  (4476.865883111954, 4307.140010595322, 4162.76...   \n",
       "\n",
       "                                   train_log_marglik  \\\n",
       "0  (-230.2573699951172, -230.25762939453125, -230...   \n",
       "1  (-1781.3154296875, -1749.48681640625, -1749.39...   \n",
       "2  (-11346.69140625, -11566.8984375, -11260.21679...   \n",
       "3  (-31109.111328125, -29757.19921875, -30299.488...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.3404999673366546, 0.3673000037670135, 0.342...   \n",
       "1  (0.722000002861023, 0.7240999937057495, 0.7134...   \n",
       "2  (0.7628000378608704, 0.7649999856948853, 0.764...   \n",
       "3  (0.9372000694274902, 0.9431999921798706, 0.943...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (2.302569054031372, 2.3025725662231444, 2.3025...       0.350033   \n",
       "1  (1.1939880359649662, 1.1717322761535645, 1.172...       0.719833   \n",
       "2  (0.7776520441055297, 0.7819208739280702, 0.784...       0.764100   \n",
       "3  (0.1869448745250701, 0.1738006152153015, 0.174...       0.941400   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.012231        0.3405        0.3673       2.302567      0.000005   \n",
       "1      0.004629        0.7134        0.7241       1.179297      0.010390   \n",
       "2      0.000942        0.7628        0.7650       0.781211      0.002664   \n",
       "3      0.002980        0.9372        0.9438       0.178508      0.005979   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      2.302560      2.302573  \n",
       "1      1.171732      1.193988  \n",
       "2      0.777652      0.784060  \n",
       "3      0.173801      0.186945  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>100</td>\n",
       "      <td>0.350033</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>0.3673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.719833</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.764100</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0     l2-sp    100       0.350033        0.3405        0.3673\n",
       "1     l2-sp   1000       0.719833        0.7134        0.7241\n",
       "2     l2-sp  10000       0.764100        0.7628        0.7650\n",
       "3     l2-sp  50000       0.941400        0.9372        0.9438"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>100</td>\n",
       "      <td>2.302567</td>\n",
       "      <td>2.302560</td>\n",
       "      <td>2.302573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.179297</td>\n",
       "      <td>1.171732</td>\n",
       "      <td>1.193988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.781211</td>\n",
       "      <td>0.777652</td>\n",
       "      <td>0.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.178508</td>\n",
       "      <td>0.173801</td>\n",
       "      <td>0.186945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0     l2-sp    100       2.302567      2.302560      2.302573\n",
       "1     l2-sp   1000       1.179297      1.171732      1.193988\n",
       "2     l2-sp  10000       0.781211      0.777652      0.784060\n",
       "3     l2-sp  50000       0.178508      0.173801      0.186945"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=370_random_state=1001</td>\n",
       "      <td>370</td>\n",
       "      <td>1001</td>\n",
       "      <td>-459.612122</td>\n",
       "      <td>0.884692</td>\n",
       "      <td>0.409536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=370_random_state=2001</td>\n",
       "      <td>370</td>\n",
       "      <td>2001</td>\n",
       "      <td>-460.313660</td>\n",
       "      <td>0.878255</td>\n",
       "      <td>0.420677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=370_random_state=3001</td>\n",
       "      <td>370</td>\n",
       "      <td>3001</td>\n",
       "      <td>-475.961823</td>\n",
       "      <td>0.881983</td>\n",
       "      <td>0.369925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=3441_random_state=1001</td>\n",
       "      <td>3441</td>\n",
       "      <td>1001</td>\n",
       "      <td>-1272.866211</td>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.282283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=3441_random_state=2001</td>\n",
       "      <td>3441</td>\n",
       "      <td>2001</td>\n",
       "      <td>-1324.654175</td>\n",
       "      <td>0.931520</td>\n",
       "      <td>0.291258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=3441_random_state=3001</td>\n",
       "      <td>3441</td>\n",
       "      <td>3001</td>\n",
       "      <td>-1320.142212</td>\n",
       "      <td>0.930102</td>\n",
       "      <td>0.285095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                  model_name     n  random_state  \\\n",
       "6    l2-zero   l2-zero_lr_0=0.01_n=370_random_state=1001   370          1001   \n",
       "7    l2-zero   l2-zero_lr_0=0.01_n=370_random_state=2001   370          2001   \n",
       "8    l2-zero   l2-zero_lr_0=0.01_n=370_random_state=3001   370          3001   \n",
       "9    l2-zero  l2-zero_lr_0=0.01_n=3441_random_state=1001  3441          1001   \n",
       "10   l2-zero  l2-zero_lr_0=0.01_n=3441_random_state=2001  3441          2001   \n",
       "11   l2-zero  l2-zero_lr_0=0.01_n=3441_random_state=3001  3441          3001   \n",
       "\n",
       "    train_log_marglik  test_acc  test_nll  \n",
       "6         -459.612122  0.884692  0.409536  \n",
       "7         -460.313660  0.878255  0.420677  \n",
       "8         -475.961823  0.881983  0.369925  \n",
       "9        -1272.866211  0.932886  0.282283  \n",
       "10       -1324.654175  0.931520  0.291258  \n",
       "11       -1320.142212  0.930102  0.285095  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'l2-zero'\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/Oxford-IIIT_Pet'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_Oxford-IIIT_Pet_diagEF'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [370, 3441]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_log_marglik', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_log_marglik.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "    \n",
    "filtered_df = retrained_df[retrained_df['train_log_marglik'].notna()]\n",
    "min_indices = filtered_df.groupby(['criterion', 'n', 'random_state'])['train_log_marglik'].idxmax()\n",
    "retrained_df = filtered_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>370</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=370_random_state=1001, l2...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-459.6121215820313, -460.3136596679688, -475....</td>\n",
       "      <td>(0.8846922516822815, 0.8782547116279602, 0.881...</td>\n",
       "      <td>(0.4095357748509493, 0.420676869790799, 0.3699...</td>\n",
       "      <td>0.881643</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.878255</td>\n",
       "      <td>0.884692</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>0.369925</td>\n",
       "      <td>0.420677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>3441</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=3441_random_state=1001, l...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-1272.8662109375, -1324.6541748046875, -1320....</td>\n",
       "      <td>(0.9328855276107788, 0.9315203428268432, 0.930...</td>\n",
       "      <td>(0.282282579809013, 0.291258049339389, 0.28509...</td>\n",
       "      <td>0.931503</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.930102</td>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.286212</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.282283</td>\n",
       "      <td>0.291258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n                                         model_name  \\\n",
       "0   l2-zero   370  (l2-zero_lr_0=0.01_n=370_random_state=1001, l2...   \n",
       "1   l2-zero  3441  (l2-zero_lr_0=0.01_n=3441_random_state=1001, l...   \n",
       "\n",
       "         random_state                                  train_log_marglik  \\\n",
       "0  (1001, 2001, 3001)  (-459.6121215820313, -460.3136596679688, -475....   \n",
       "1  (1001, 2001, 3001)  (-1272.8662109375, -1324.6541748046875, -1320....   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.8846922516822815, 0.8782547116279602, 0.881...   \n",
       "1  (0.9328855276107788, 0.9315203428268432, 0.930...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (0.4095357748509493, 0.420676869790799, 0.3699...       0.881643   \n",
       "1  (0.282282579809013, 0.291258049339389, 0.28509...       0.931503   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.002639      0.878255      0.884692       0.400046      0.021779   \n",
       "1      0.001136      0.930102      0.932886       0.286212      0.003748   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      0.369925      0.420677  \n",
       "1      0.282283      0.291258  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>370</td>\n",
       "      <td>0.881643</td>\n",
       "      <td>0.878255</td>\n",
       "      <td>0.884692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>3441</td>\n",
       "      <td>0.931503</td>\n",
       "      <td>0.930102</td>\n",
       "      <td>0.932886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0   l2-zero   370       0.881643      0.878255      0.884692\n",
       "1   l2-zero  3441       0.931503      0.930102      0.932886"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>370</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.369925</td>\n",
       "      <td>0.420677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>3441</td>\n",
       "      <td>0.286212</td>\n",
       "      <td>0.282283</td>\n",
       "      <td>0.291258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0   l2-zero   370       0.400046      0.369925      0.420677\n",
       "1   l2-zero  3441       0.286212      0.282283      0.291258"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=370_random_state=1001</td>\n",
       "      <td>370</td>\n",
       "      <td>1001</td>\n",
       "      <td>-929.215149</td>\n",
       "      <td>0.864195</td>\n",
       "      <td>1.353605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=370_random_state=2001</td>\n",
       "      <td>370</td>\n",
       "      <td>2001</td>\n",
       "      <td>-915.322754</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>1.284406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=370_random_state=3001</td>\n",
       "      <td>370</td>\n",
       "      <td>3001</td>\n",
       "      <td>-917.240967</td>\n",
       "      <td>0.872751</td>\n",
       "      <td>1.369776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=3441_random_state=1001</td>\n",
       "      <td>3441</td>\n",
       "      <td>1001</td>\n",
       "      <td>-2850.339844</td>\n",
       "      <td>0.906682</td>\n",
       "      <td>0.411867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=3441_random_state=2001</td>\n",
       "      <td>3441</td>\n",
       "      <td>2001</td>\n",
       "      <td>-2810.989258</td>\n",
       "      <td>0.906163</td>\n",
       "      <td>0.411842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=3441_random_state=3001</td>\n",
       "      <td>3441</td>\n",
       "      <td>3001</td>\n",
       "      <td>-2839.485107</td>\n",
       "      <td>0.905492</td>\n",
       "      <td>0.411417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion                               model_name     n  random_state  \\\n",
       "6     l2-sp  l2-sp_lr_0=0.01_n=370_random_state=1001   370          1001   \n",
       "1     l2-sp   l2-sp_lr_0=0.1_n=370_random_state=2001   370          2001   \n",
       "2     l2-sp   l2-sp_lr_0=0.1_n=370_random_state=3001   370          3001   \n",
       "3     l2-sp  l2-sp_lr_0=0.1_n=3441_random_state=1001  3441          1001   \n",
       "4     l2-sp  l2-sp_lr_0=0.1_n=3441_random_state=2001  3441          2001   \n",
       "5     l2-sp  l2-sp_lr_0=0.1_n=3441_random_state=3001  3441          3001   \n",
       "\n",
       "   train_log_marglik  test_acc  test_nll  \n",
       "6        -929.215149  0.864195  1.353605  \n",
       "1        -915.322754  0.863962  1.284406  \n",
       "2        -917.240967  0.872751  1.369776  \n",
       "3       -2850.339844  0.906682  0.411867  \n",
       "4       -2810.989258  0.906163  0.411842  \n",
       "5       -2839.485107  0.905492  0.411417  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'l2-sp'\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/Oxford-IIIT_Pet'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_Oxford-IIIT_Pet_diagEF'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [370, 3441]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_log_marglik', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_log_marglik.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "    \n",
    "filtered_df = retrained_df[retrained_df['train_log_marglik'].notna()]\n",
    "min_indices = filtered_df.groupby(['criterion', 'n', 'random_state'])['train_log_marglik'].idxmax()\n",
    "retrained_df = filtered_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>370</td>\n",
       "      <td>(l2-sp_lr_0=0.01_n=370_random_state=1001, l2-s...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-929.2151489257812, -915.32275390625, -917.24...</td>\n",
       "      <td>(0.8641949892044067, 0.8639618158340454, 0.872...</td>\n",
       "      <td>(1.35360466836096, 1.2844058398688385, 1.36977...</td>\n",
       "      <td>0.866969</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>0.872751</td>\n",
       "      <td>1.335929</td>\n",
       "      <td>0.037026</td>\n",
       "      <td>1.284406</td>\n",
       "      <td>1.369776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>3441</td>\n",
       "      <td>(l2-sp_lr_0=0.1_n=3441_random_state=1001, l2-s...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-2850.33984375, -2810.9892578125, -2839.48510...</td>\n",
       "      <td>(0.9066816568374634, 0.906163454055786, 0.9054...</td>\n",
       "      <td>(0.4118665885733595, 0.4118419586150059, 0.411...</td>\n",
       "      <td>0.906112</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.905492</td>\n",
       "      <td>0.906682</td>\n",
       "      <td>0.411708</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.411417</td>\n",
       "      <td>0.411867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n                                         model_name  \\\n",
       "0     l2-sp   370  (l2-sp_lr_0=0.01_n=370_random_state=1001, l2-s...   \n",
       "1     l2-sp  3441  (l2-sp_lr_0=0.1_n=3441_random_state=1001, l2-s...   \n",
       "\n",
       "         random_state                                  train_log_marglik  \\\n",
       "0  (1001, 2001, 3001)  (-929.2151489257812, -915.32275390625, -917.24...   \n",
       "1  (1001, 2001, 3001)  (-2850.33984375, -2810.9892578125, -2839.48510...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.8641949892044067, 0.8639618158340454, 0.872...   \n",
       "1  (0.9066816568374634, 0.906163454055786, 0.9054...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (1.35360466836096, 1.2844058398688385, 1.36977...       0.866969   \n",
       "1  (0.4118665885733595, 0.4118419586150059, 0.411...       0.906112   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.004089      0.863962      0.872751       1.335929      0.037026   \n",
       "1      0.000487      0.905492      0.906682       0.411708      0.000206   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      1.284406      1.369776  \n",
       "1      0.411417      0.411867  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>370</td>\n",
       "      <td>0.866969</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>0.872751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>3441</td>\n",
       "      <td>0.906112</td>\n",
       "      <td>0.905492</td>\n",
       "      <td>0.906682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0     l2-sp   370       0.866969      0.863962      0.872751\n",
       "1     l2-sp  3441       0.906112      0.905492      0.906682"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>370</td>\n",
       "      <td>1.335929</td>\n",
       "      <td>1.284406</td>\n",
       "      <td>1.369776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>3441</td>\n",
       "      <td>0.411708</td>\n",
       "      <td>0.411417</td>\n",
       "      <td>0.411867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0     l2-sp   370       1.335929      1.284406      1.369776\n",
       "1     l2-sp  3441       0.411708      0.411417      0.411867"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=510_random_state=1001</td>\n",
       "      <td>510</td>\n",
       "      <td>1001</td>\n",
       "      <td>-784.824951</td>\n",
       "      <td>0.846590</td>\n",
       "      <td>0.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=510_random_state=2001</td>\n",
       "      <td>510</td>\n",
       "      <td>2001</td>\n",
       "      <td>-779.792603</td>\n",
       "      <td>0.853450</td>\n",
       "      <td>0.686262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=510_random_state=3001</td>\n",
       "      <td>510</td>\n",
       "      <td>3001</td>\n",
       "      <td>-796.898254</td>\n",
       "      <td>0.858159</td>\n",
       "      <td>0.700889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=1020_random_state=1001</td>\n",
       "      <td>1020</td>\n",
       "      <td>1001</td>\n",
       "      <td>-957.297668</td>\n",
       "      <td>0.926593</td>\n",
       "      <td>0.367216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=1020_random_state=2001</td>\n",
       "      <td>1020</td>\n",
       "      <td>2001</td>\n",
       "      <td>-970.836426</td>\n",
       "      <td>0.923874</td>\n",
       "      <td>0.354911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_lr_0=0.01_n=1020_random_state=3001</td>\n",
       "      <td>1020</td>\n",
       "      <td>3001</td>\n",
       "      <td>-960.152344</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.363436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                  model_name     n  random_state  \\\n",
       "6    l2-zero   l2-zero_lr_0=0.01_n=510_random_state=1001   510          1001   \n",
       "7    l2-zero   l2-zero_lr_0=0.01_n=510_random_state=2001   510          2001   \n",
       "8    l2-zero   l2-zero_lr_0=0.01_n=510_random_state=3001   510          3001   \n",
       "9    l2-zero  l2-zero_lr_0=0.01_n=1020_random_state=1001  1020          1001   \n",
       "10   l2-zero  l2-zero_lr_0=0.01_n=1020_random_state=2001  1020          2001   \n",
       "11   l2-zero  l2-zero_lr_0=0.01_n=1020_random_state=3001  1020          3001   \n",
       "\n",
       "    train_log_marglik  test_acc  test_nll  \n",
       "6         -784.824951  0.846590  0.730909  \n",
       "7         -779.792603  0.853450  0.686262  \n",
       "8         -796.898254  0.858159  0.700889  \n",
       "9         -957.297668  0.926593  0.367216  \n",
       "10        -970.836426  0.923874  0.354911  \n",
       "11        -960.152344  0.924812  0.363436  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'l2-zero'\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/Flowers_102'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_Flowers_102_diagEF'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [510, 1020]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_log_marglik', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_log_marglik.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "        \n",
    "filtered_df = retrained_df[retrained_df['train_log_marglik'].notna()]\n",
    "min_indices = filtered_df.groupby(['criterion', 'n', 'random_state'])['train_log_marglik'].idxmax()\n",
    "retrained_df = filtered_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>510</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=510_random_state=1001, l2...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-784.824951171875, -779.7926025390625, -796.8...</td>\n",
       "      <td>(0.8465895652770996, 0.853449821472168, 0.8581...</td>\n",
       "      <td>(0.730909150323709, 0.6862618204261965, 0.7008...</td>\n",
       "      <td>0.852733</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.846590</td>\n",
       "      <td>0.858159</td>\n",
       "      <td>0.706020</td>\n",
       "      <td>0.018585</td>\n",
       "      <td>0.686262</td>\n",
       "      <td>0.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1020</td>\n",
       "      <td>(l2-zero_lr_0=0.01_n=1020_random_state=1001, l...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-957.2976684570312, -970.83642578125, -960.15...</td>\n",
       "      <td>(0.9265932440757751, 0.9238739013671876, 0.924...</td>\n",
       "      <td>(0.3672155920624524, 0.3549106962886675, 0.363...</td>\n",
       "      <td>0.925093</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.923874</td>\n",
       "      <td>0.926593</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.354911</td>\n",
       "      <td>0.367216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n                                         model_name  \\\n",
       "0   l2-zero   510  (l2-zero_lr_0=0.01_n=510_random_state=1001, l2...   \n",
       "1   l2-zero  1020  (l2-zero_lr_0=0.01_n=1020_random_state=1001, l...   \n",
       "\n",
       "         random_state                                  train_log_marglik  \\\n",
       "0  (1001, 2001, 3001)  (-784.824951171875, -779.7926025390625, -796.8...   \n",
       "1  (1001, 2001, 3001)  (-957.2976684570312, -970.83642578125, -960.15...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.8465895652770996, 0.853449821472168, 0.8581...   \n",
       "1  (0.9265932440757751, 0.9238739013671876, 0.924...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (0.730909150323709, 0.6862618204261965, 0.7008...       0.852733   \n",
       "1  (0.3672155920624524, 0.3549106962886675, 0.363...       0.925093   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.004750      0.846590      0.858159       0.706020      0.018585   \n",
       "1      0.001128      0.923874      0.926593       0.361854      0.005146   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      0.686262      0.730909  \n",
       "1      0.354911      0.367216  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>510</td>\n",
       "      <td>0.852733</td>\n",
       "      <td>0.846590</td>\n",
       "      <td>0.858159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.925093</td>\n",
       "      <td>0.923874</td>\n",
       "      <td>0.926593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0   l2-zero   510       0.852733      0.846590      0.858159\n",
       "1   l2-zero  1020       0.925093      0.923874      0.926593"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>510</td>\n",
       "      <td>0.706020</td>\n",
       "      <td>0.686262</td>\n",
       "      <td>0.730909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.354911</td>\n",
       "      <td>0.367216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0   l2-zero   510       0.706020      0.686262      0.730909\n",
       "1   l2-zero  1020       0.361854      0.354911      0.367216"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=510_random_state=1001</td>\n",
       "      <td>510</td>\n",
       "      <td>1001</td>\n",
       "      <td>-2358.463867</td>\n",
       "      <td>0.296046</td>\n",
       "      <td>4.624085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=510_random_state=2001</td>\n",
       "      <td>510</td>\n",
       "      <td>2001</td>\n",
       "      <td>-2358.495850</td>\n",
       "      <td>0.203985</td>\n",
       "      <td>4.624209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.1_n=510_random_state=3001</td>\n",
       "      <td>510</td>\n",
       "      <td>3001</td>\n",
       "      <td>-2358.385254</td>\n",
       "      <td>0.187693</td>\n",
       "      <td>4.623873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=1020_random_state=1001</td>\n",
       "      <td>1020</td>\n",
       "      <td>1001</td>\n",
       "      <td>-4229.246582</td>\n",
       "      <td>0.826620</td>\n",
       "      <td>2.602177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=1020_random_state=2001</td>\n",
       "      <td>1020</td>\n",
       "      <td>2001</td>\n",
       "      <td>-4264.004883</td>\n",
       "      <td>0.825626</td>\n",
       "      <td>2.599816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_lr_0=0.01_n=1020_random_state=3001</td>\n",
       "      <td>1020</td>\n",
       "      <td>3001</td>\n",
       "      <td>-4304.702148</td>\n",
       "      <td>0.827271</td>\n",
       "      <td>2.610205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                model_name     n  random_state  \\\n",
       "0      l2-sp    l2-sp_lr_0=0.1_n=510_random_state=1001   510          1001   \n",
       "1      l2-sp    l2-sp_lr_0=0.1_n=510_random_state=2001   510          2001   \n",
       "2      l2-sp    l2-sp_lr_0=0.1_n=510_random_state=3001   510          3001   \n",
       "9      l2-sp  l2-sp_lr_0=0.01_n=1020_random_state=1001  1020          1001   \n",
       "10     l2-sp  l2-sp_lr_0=0.01_n=1020_random_state=2001  1020          2001   \n",
       "11     l2-sp  l2-sp_lr_0=0.01_n=1020_random_state=3001  1020          3001   \n",
       "\n",
       "    train_log_marglik  test_acc  test_nll  \n",
       "0        -2358.463867  0.296046  4.624085  \n",
       "1        -2358.495850  0.203985  4.624209  \n",
       "2        -2358.385254  0.187693  4.623873  \n",
       "9        -4229.246582  0.826620  2.602177  \n",
       "10       -4264.004883  0.825626  2.599816  \n",
       "11       -4304.702148  0.827271  2.610205  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'l2-sp'\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/Flowers_102'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_Flowers_102_diagEF'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [510, 1020]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_log_marglik', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_log_marglik.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "        \n",
    "filtered_df = retrained_df[retrained_df['train_log_marglik'].notna()]\n",
    "min_indices = filtered_df.groupby(['criterion', 'n', 'random_state'])['train_log_marglik'].idxmax()\n",
    "retrained_df = filtered_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_log_marglik</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>510</td>\n",
       "      <td>(l2-sp_lr_0=0.1_n=510_random_state=1001, l2-sp...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-2358.4638671875, -2358.495849609375, -2358.3...</td>\n",
       "      <td>(0.2960460782051086, 0.2039852440357208, 0.187...</td>\n",
       "      <td>(4.624085110481203, 4.624208929403407, 4.62387...</td>\n",
       "      <td>0.229241</td>\n",
       "      <td>0.047704</td>\n",
       "      <td>0.187693</td>\n",
       "      <td>0.296046</td>\n",
       "      <td>4.624056</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>4.623873</td>\n",
       "      <td>4.624209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1020</td>\n",
       "      <td>(l2-sp_lr_0=0.01_n=1020_random_state=1001, l2-...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(-4229.24658203125, -4264.0048828125, -4304.70...</td>\n",
       "      <td>(0.8266200423240662, 0.8256259560585022, 0.827...</td>\n",
       "      <td>(2.602176932750397, 2.599815851441242, 2.61020...</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.825626</td>\n",
       "      <td>0.827271</td>\n",
       "      <td>2.604066</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>2.599816</td>\n",
       "      <td>2.610205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n                                         model_name  \\\n",
       "0     l2-sp   510  (l2-sp_lr_0=0.1_n=510_random_state=1001, l2-sp...   \n",
       "1     l2-sp  1020  (l2-sp_lr_0=0.01_n=1020_random_state=1001, l2-...   \n",
       "\n",
       "         random_state                                  train_log_marglik  \\\n",
       "0  (1001, 2001, 3001)  (-2358.4638671875, -2358.495849609375, -2358.3...   \n",
       "1  (1001, 2001, 3001)  (-4229.24658203125, -4264.0048828125, -4304.70...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.2960460782051086, 0.2039852440357208, 0.187...   \n",
       "1  (0.8266200423240662, 0.8256259560585022, 0.827...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (4.624085110481203, 4.624208929403407, 4.62387...       0.229241   \n",
       "1  (2.602176932750397, 2.599815851441242, 2.61020...       0.826506   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.047704      0.187693      0.296046       4.624056      0.000139   \n",
       "1      0.000677      0.825626      0.827271       2.604066      0.004447   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      4.623873      4.624209  \n",
       "1      2.599816      2.610205  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>510</td>\n",
       "      <td>0.229241</td>\n",
       "      <td>0.187693</td>\n",
       "      <td>0.296046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.826506</td>\n",
       "      <td>0.825626</td>\n",
       "      <td>0.827271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0     l2-sp   510       0.229241      0.187693      0.296046\n",
       "1     l2-sp  1020       0.826506      0.825626      0.827271"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>510</td>\n",
       "      <td>4.624056</td>\n",
       "      <td>4.623873</td>\n",
       "      <td>4.624209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1020</td>\n",
       "      <td>2.604066</td>\n",
       "      <td>2.599816</td>\n",
       "      <td>2.610205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion     n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0     l2-sp   510       4.624056      4.623873      4.624209\n",
       "1     l2-sp  1020       2.604066      2.599816      2.610205"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "n = 1_000\n",
    "tune = False\n",
    "random_state = 1001\n",
    "augmented_train_dataset, train_dataset, val_or_test_dataset = utils.get_cifar10_datasets(dataset_directory, n, tune, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 0\n",
    "augmented_train_loader = torch.utils.data.DataLoader(augmented_train_dataset, batch_size=min(batch_size, len(augmented_train_dataset)), shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "train_loader = torch.utils.data.DataLoader(augmented_train_dataset, batch_size=min(batch_size, len(augmented_train_dataset)), shuffle=True, num_workers=num_workers)\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=min(batch_size, len(train_dataset)), num_workers=num_workers)\n",
    "val_or_test_loader = torch.utils.data.DataLoader(val_or_test_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = 6000\n",
    "num_batches = len(augmented_train_loader)\n",
    "epochs = int(steps/num_batches)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "bb_loc = torch.load('/cluster/tufts/hugheslab/eharve06/resnet50_torchvision/resnet50_torchvision_mean.pt', map_location=torch.device('cpu'), weights_only=False).to(device)\n",
    "clf_loc = torch.ones((2048 * num_classes) + num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = torchvision.models.vit_b_16()\n",
    "model.heads.head = torch.nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "bb_loc = torch.load('/cluster/tufts/hugheslab/eharve06/vit_b_16_torchvision/vit_b_16_torchvision_mean.pt', map_location=torch.device('cpu'), weights_only=False).to(device )\n",
    "clf_loc = torch.ones((768 * num_classes) + num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = torchvision.models.convnext_tiny()\n",
    "model.classifier[2] = torch.nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "bb_loc = torch.load('/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision/convnext_tiny_torchvision_mean.pt', map_location=torch.device('cpu'), weights_only=False).to(device)\n",
    "clf_loc = torch.ones((768 * num_classes) + num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m         beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_precision[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([alpha \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype),\n\u001b[1;32m     21\u001b[0m                           beta \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_params \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)])\n\u001b[1;32m     23\u001b[0m la \u001b[38;5;241m=\u001b[39m DiagLaplace(\n\u001b[0;32m---> 24\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     25\u001b[0m     likelihood\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     prior_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     27\u001b[0m     backend\u001b[38;5;241m=\u001b[39mAsdlEF,\n\u001b[1;32m     28\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from laplace.baselaplace import DiagLaplace\n",
    "\n",
    "class L2SPLaplace(DiagLaplace):\n",
    "    \n",
    "    @property\n",
    "    def prior_precision(self) -> torch.Tensor:\n",
    "        return self._prior_precision\n",
    "\n",
    "    @prior_precision.setter\n",
    "    def prior_precision(self, prior_precision: float | torch.Tensor):\n",
    "        self._posterior_scale = None\n",
    "        self._prior_precision = prior_precision.to(\n",
    "            device=self._device, dtype=self._dtype\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def prior_precision_diag(self) -> torch.Tensor:\n",
    "        alpha = self.prior_precision[0]\n",
    "        beta = self.prior_precision[1]\n",
    "        return torch.cat([alpha * torch.ones(self.D, device=self._device, dtype=self._dtype),\n",
    "                          beta * torch.ones(self.n_params - self.D, device=self._device, dtype=self._dtype)])\n",
    "\n",
    "prior_precision = torch.tensor([1.0, 1.0]).to(device)\n",
    "prior_mean = torch.cat((bb_loc, clf_loc))\n",
    "la = L2SPLaplace(\n",
    "    model=model,\n",
    "    likelihood='classification',\n",
    "    prior_precision=prior_precision,\n",
    "    prior_mean=prior_mean,\n",
    "    backend=AsdlEF,\n",
    ")\n",
    "la.D = len(bb_loc)\n",
    "alpha = la.prior_precision[0].item() / len(train_dataset)\n",
    "beta = la.prior_precision[1].item() / len(train_dataset)\n",
    "\n",
    "steps = 6000\n",
    "num_batches = len(augmented_train_loader)\n",
    "epochs = int(steps/num_batches)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "F, K, gamma = 10, 100, 1\n",
    "if epoch % F == 0:\n",
    "    \n",
    "    print(la.prior_precision)\n",
    "    la.fit(train_loader)\n",
    "    la.optimize_prior_precision(\n",
    "        pred_type='glm', \n",
    "        method='marglik', \n",
    "        n_steps=K, \n",
    "        lr=gamma, \n",
    "        init_prior_prec=la.prior_precision\n",
    "    )\n",
    "    alpha = la.prior_precision[0].item() / len(train_dataset)\n",
    "    beta = la.prior_precision[1].item() / len(train_dataset)\n",
    "    print(la.prior_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Hugging Face\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "def get_news_ag_datasets(dataset_directory, n, tune, random_state):\n",
    "\n",
    "    ag_news_dataset = datasets.load_dataset('ag_news', cache_dir=dataset_directory)\n",
    "    full_train_dataset = pd.DataFrame(ag_news_dataset['train'])\n",
    "    full_test_dataset = pd.DataFrame(ag_news_dataset['test'])\n",
    "\n",
    "    if n == len(full_train_dataset):\n",
    "        train_and_val_indices = np.arange(0, len(full_train_dataset))\n",
    "    else:\n",
    "        train_and_val_indices, _ = train_test_split(\n",
    "            np.arange(0, len(full_train_dataset)), \n",
    "            test_size=None, \n",
    "            train_size=n, \n",
    "            random_state=random_state, \n",
    "            shuffle=True, \n",
    "            stratify=np.array(full_train_dataset.label),\n",
    "        )\n",
    "        \n",
    "    val_size = int((1/5) * n)\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        train_and_val_indices, \n",
    "        test_size=val_size, \n",
    "        train_size=n-val_size, \n",
    "        random_state=random_state, \n",
    "        shuffle=True, \n",
    "        stratify=np.array(full_train_dataset.label)[train_and_val_indices],\n",
    "    )\n",
    "    \n",
    "    if tune:\n",
    "        return datasets.DatasetDict({\n",
    "            'train': datasets.Dataset.from_pandas(full_train_dataset.iloc[train_indices]),\n",
    "            'val_or_test': datasets.Dataset.from_pandas(full_train_dataset.iloc[val_indices])\n",
    "        })\n",
    "    else:\n",
    "        return datasets.DatasetDict({\n",
    "            'train': datasets.Dataset.from_pandas(full_train_dataset.iloc[train_and_val_indices]),\n",
    "            'val_or_test': datasets.Dataset.from_pandas(full_test_dataset)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 400/400 [00:00<00:00, 1645.37 examples/s]\n",
      "Map: 100%|██████████| 7600/7600 [00:04<00:00, 1692.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/AG_News'\n",
    "n = 400\n",
    "tune = False\n",
    "random_state = 1001\n",
    "dataset = get_news_ag_datasets(dataset_directory, n, tune, random_state)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "tokenized_datasets['train'].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_datasets['val_or_test'].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "batch_size = 32\n",
    "augmented_train_loader = torch.utils.data.DataLoader(tokenized_datasets['train'], batch_size=batch_size, shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(tokenized_datasets['train'], batch_size=batch_size)\n",
    "val_or_test_loader = torch.utils.data.DataLoader(tokenized_datasets['val_or_test'], batch_size=batch_size)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=4, bias=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/laplace/baselaplace.py:435: UserWarning: By default `link_approx` is `probit`. Make sure to set it equals to the way you want to call `la(test_data, pred_type=..., link_approx=...)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3453])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing\n",
    "\n",
    "class MyBERT(torch.nn.Module):\n",
    "    def __init__(self, tokenizer: transformers.PreTrainedTokenizer, num_labels: int):\n",
    "        super().__init__()\n",
    "        config = transformers.BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "        config.pad_token_id = tokenizer.pad_token_id\n",
    "        config.num_labels = num_labels\n",
    "        self.hf_model = transformers.BertForSequenceClassification.from_pretrained(\n",
    "            \"bert-base-uncased\", config=config\n",
    "        )\n",
    "\n",
    "    def forward(self, data: typing.MutableMapping) -> torch.Tensor:\n",
    "        device = next(self.parameters()).device\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attn_mask = data[\"attention_mask\"].to(device)\n",
    "        output_dict = self.hf_model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "        return output_dict.logits\n",
    "    \n",
    "num_classes = 4\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = MyBERT(tokenizer, num_classes)\n",
    "    \n",
    "la = DiagLaplace(\n",
    "    model=model,\n",
    "    likelihood='classification',\n",
    "    prior_precision=1.0,\n",
    "    backend=AsdlEF,\n",
    ")\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "F, K, gamma = 10, 100, 1\n",
    "if epoch % F == 0:\n",
    "    \n",
    "    print(la.prior_precision)\n",
    "    la.fit(train_loader)\n",
    "    la.optimize_prior_precision(\n",
    "        pred_type='glm', \n",
    "        method='marglik', \n",
    "        n_steps=K, \n",
    "        lr=gamma, \n",
    "        init_prior_prec=la.prior_precision\n",
    "    )\n",
    "    print(la.prior_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Not supported module: NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#model = torchvision.models.convnext_tiny()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m PreconditioningConfig(data_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, damping\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m gm \u001b[38;5;241m=\u001b[39m KfacGradientMaker(model, config, fisher_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfisher_emp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/asdl/precondition/natural_gradient.py:891\u001b[0m, in \u001b[0;36mKfacGradientMaker.__init__\u001b[0;34m(self, model, config, fisher_type, loss_type, scale, grad_scale, n_mc_samples, var, seed, swift)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, config: PreconditioningConfig,\n\u001b[1;32m    884\u001b[0m              fisher_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m FISHER_MC, loss_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m LOSS_CROSS_ENTROPY,\n\u001b[1;32m    885\u001b[0m              scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, grad_scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    886\u001b[0m              n_mc_samples: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, var: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, swift\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     fisher_shape \u001b[38;5;241m=\u001b[39m [SHAPE_SWIFT_KRON \u001b[38;5;28;01mif\u001b[39;00m swift \u001b[38;5;28;01melse\u001b[39;00m SHAPE_KRON,\n\u001b[1;32m    888\u001b[0m                     (nn\u001b[38;5;241m.\u001b[39mBatchNorm1d, SHAPE_UNIT_WISE),\n\u001b[1;32m    889\u001b[0m                     (nn\u001b[38;5;241m.\u001b[39mBatchNorm2d, SHAPE_UNIT_WISE),\n\u001b[1;32m    890\u001b[0m                     (nn\u001b[38;5;241m.\u001b[39mLayerNorm, SHAPE_UNIT_WISE)]\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, config,\n\u001b[1;32m    892\u001b[0m                      fisher_type\u001b[38;5;241m=\u001b[39mfisher_type,\n\u001b[1;32m    893\u001b[0m                      fisher_shape\u001b[38;5;241m=\u001b[39mfisher_shape,\n\u001b[1;32m    894\u001b[0m                      loss_type\u001b[38;5;241m=\u001b[39mloss_type,\n\u001b[1;32m    895\u001b[0m                      scale\u001b[38;5;241m=\u001b[39mscale,\n\u001b[1;32m    896\u001b[0m                      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    897\u001b[0m                      n_mc_samples\u001b[38;5;241m=\u001b[39mn_mc_samples,\n\u001b[1;32m    898\u001b[0m                      var\u001b[38;5;241m=\u001b[39mvar,\n\u001b[1;32m    899\u001b[0m                      seed\u001b[38;5;241m=\u001b[39mseed\n\u001b[1;32m    900\u001b[0m                      )\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/asdl/precondition/natural_gradient.py:127\u001b[0m, in \u001b[0;36mNaturalGradientMaker.__init__\u001b[0;34m(self, model, config, fisher_type, fisher_shape, loss_type, scale, grad_scale, sync_group, sync_group_ranks, module_partitions, n_mc_samples, var, seed)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_distr_prec_partition()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sync_group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sync_group_ranks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/asdl/precondition/natural_gradient.py:193\u001b[0m, in \u001b[0;36mNaturalGradientMaker.get_distr_prec_partition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m enum_module, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_for(shape)):\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m#if not self.is_module_for_inv_and_precondition(module):\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mrequires_grad:     \n\u001b[0;32m--> 193\u001b[0m         comp_cost_layers\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputational_cost(shape, module))\n\u001b[1;32m    194\u001b[0m         p_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/cluster/tufts/hugheslabkp/eharve06/miniconda3/envs/l3d_2024f_cuda12_1/lib/python3.12/site-packages/asdl/precondition/natural_gradient.py:294\u001b[0m, in \u001b[0;36mNaturalGradientMaker.computational_cost\u001b[0;34m(self, shape, module)\u001b[0m\n\u001b[1;32m    292\u001b[0m supported_layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNorm1d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNorm2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayerNorm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    293\u001b[0m module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(module)\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m module_name \u001b[38;5;129;01min\u001b[39;00m supported_layers, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot supported module: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(module)\n\u001b[1;32m    296\u001b[0m p \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mweight\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_module_for_inv_and_precondition(module):\n",
      "\u001b[0;31mAssertionError\u001b[0m: Not supported module: NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)"
     ]
    }
   ],
   "source": [
    "from asdl.precondition import PreconditioningConfig, KfacGradientMaker\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "model = torchvision.models.vit_b_16()\n",
    "#model = torchvision.models.convnext_tiny()\n",
    "config = PreconditioningConfig(data_size=128, damping=0.01)\n",
    "gm = KfacGradientMaker(model, config, fisher_type=\"fisher_emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50()\n",
    "#model = torchvision.models.vit_b_16()\n",
    "#model = torchvision.models.convnext_tiny()\n",
    "\n",
    "supported_layers = ['Linear', 'Conv2d', 'BatchNorm2d', 'LayerNorm', \n",
    "                    'LayerNorm2d', 'CNBlock', 'MultiheadAttention', 'Embedding']\n",
    "# Note: VisionTransformer has a class_token, Encoder has a pos_embedding, and\n",
    "#       NonDynamicallyQuantizableLinear is handled in MultiheadAttention\n",
    "excluded_layers = ['VisionTransformer', 'Encoder', \n",
    "                   'NonDynamicallyQuantizableLinear']\n",
    "\n",
    "for module in model.modules():\n",
    "    module_requires_grad = any(p.requires_grad for p in module.parameters(recurse=False))\n",
    "    module_name = str(module).partition('(')[0]\n",
    "    if module_requires_grad and (module_name not in supported_layers and module_name not in excluded_layers):\n",
    "        print(module_name)\n",
    "        print([name for name, param in module.named_parameters(recurse=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
