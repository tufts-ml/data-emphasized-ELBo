{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "import matplotlib.ticker as ticker\n",
    "# PyTorch\n",
    "import torch\n",
    "# GPyTorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "# BOTorch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def check_epochs(df, n, batch_size=128, steps=6000, drop_last=True):\n",
    "    num_batches = math.floor(n/batch_size) if drop_last else math.ceil(n/batch_size)\n",
    "    epochs = int(steps/num_batches)\n",
    "    return df.shape[0] == epochs\n",
    "\n",
    "def print_job(alpha, beta, dataset, dataset_dir, experiments_dir, lr_0, \n",
    "              method, model, model_arch, n, prior_dir, prior_type, random_state, \n",
    "              save, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        temp_df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "        n_train = n - int((1/5) * n) if tune else n\n",
    "        if check_epochs(temp_df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "            return\n",
    "\n",
    "    command = (\n",
    "        f\"python ../src/main_image_classifiers.py \"\n",
    "        f\"--alpha={alpha} \"\n",
    "        \"--batch_size=128 \"\n",
    "        f\"--beta={beta} \"\n",
    "        f\"--dataset=\\\"{dataset}\\\" \"\n",
    "        f\"--dataset_dir=\\\"{dataset_dir}\\\" \"\n",
    "        f\"--experiments_dir=\\\"{experiments_dir}\\\" \"\n",
    "        f\"--lr_0={lr_0} \"\n",
    "        f\"--method=\\\"{method}\\\" \"\n",
    "        f\"--model=\\\"{model}\\\" \"\n",
    "        f\"--model_arch=\\\"{model_arch}\\\" \"\n",
    "        f\"--model_name=\\\"{model_name}\\\" \"\n",
    "        f\"--n={n} \"\n",
    "        \"--num_workers=0 \"\n",
    "        f\"--prior_dir=\\\"{prior_dir}\\\" \"\n",
    "        f\"--prior_type=\\\"{prior_type}\\\" \"\n",
    "        f\"--random_state={random_state} \"\n",
    "        f\"{'--save' if save else ''}\"\n",
    "        f\"{'--tune' if tune else ''}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"    '{command}'\")\n",
    "    \n",
    "def get_runtime(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        print(\"ahh\")\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        print(\"ah\")\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"train_sec/epoch\"].sum()\n",
    "\n",
    "def get_val_or_test_acc(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_acc\"].values[-1]\n",
    "    \n",
    "def get_val_or_test_nll(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return float(\"inf\")\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return float(\"inf\")\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_nll\"].values[-1]\n",
    "\n",
    "def get_candidate(train_X, train_Y, seed):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    gp = SingleTaskGP(\n",
    "        train_X=train_X,\n",
    "        train_Y=train_Y,\n",
    "        input_transform=Normalize(d=3),\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    logEI = LogExpectedImprovement(model=gp, best_f=train_Y.max())\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(3), torch.ones(3)]).to(torch.double)\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "      logEI, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    )\n",
    "    \n",
    "    return candidate.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE:\n",
    "\n",
    "# CIFAR-10 n_iters = 41 tuned\n",
    "# Flower-102 n_iters = 41 tuned\n",
    "# Pet-37 n_iters = 41 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 35 retrained\n",
    "# Flower-102 n_iters = 35 retrained\n",
    "# Pet-37 n_iters = 35 retrained\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# CIFAR-10 n_iters = 42 tuned\n",
    "# Flower-102 n_iters = 42 tuned\n",
    "# Pet-37 n_iters = 42 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 36 retrained\n",
    "# Flower-102 n_iters = 36 retrained\n",
    "# Pet-37 n_iters = 36 retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Pet-37\"\n",
    "dataset_dir = \"{home_dir}/Pet-37\"\n",
    "model = \"l2-sp\"\n",
    "method = \"MAP\"\n",
    "model_arch = \"ConvNeXt-Tiny\"\n",
    "ns = [370, 3441]\n",
    "prior_dir = \"{home_dir}/convnext_tiny_torchvision\"\n",
    "prior_type = \"convnext_tiny_torchvision\"\n",
    "random_states = [1001, 2001, 3001]\n",
    "retrained_experiments_dir = \"{home_dir}/data-emphasized-ELBo/experiments/retrained_Pet-37_ConvNeXt-Tiny_BO\"\n",
    "tuned_experiments_dir = \"{home_dir}/data-emphasized-ELBo/experiments/tuned_Pet-37_ConvNeXt-Tiny_BO\"\n",
    "\n",
    "n_iters = 35\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "bounds = torch.tensor([[-6, -6, -4], [-2, -2, -1]], dtype=torch.double)\n",
    "\n",
    "columns = [\"alpha\", \"beta\", \"lr_0\", \"n\", \"n_iter\", \"random_state\", \"runtime\", \"seed\", \"val_acc\", \"val_nll\", \"test_acc\", \"test_nll\"]\n",
    "pet37_bo_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for n, random_state, seed in itertools.product(ns, random_states, seeds):\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "\n",
    "    train_X = torch.rand(size=(1, 3,), generator=gen, dtype=torch.double)\n",
    "    train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "    \n",
    "    alpha, beta, lr_0 = 10**train_X_bounded[0]\n",
    "    print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "    train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "    \n",
    "    alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "    print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "    \n",
    "    runtime = get_runtime(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    \n",
    "    val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "    row = [alpha.item(), beta.item(), lr_0.item(), n, 0, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "    pet37_bo_df.loc[len(pet37_bo_df)] = row\n",
    "    \n",
    "    for i in range(1, n_iters+1):\n",
    "\n",
    "        candidate = get_candidate(train_X, train_Y, seed)\n",
    "        candidate_bounded = (bounds[1] - bounds[0]) * candidate + bounds[0]\n",
    "        train_X = torch.cat([train_X, candidate])\n",
    "        train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "                \n",
    "        alpha, beta, lr_0 = 10**candidate_bounded[0]        \n",
    "        print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "        train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "\n",
    "        alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "        #print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "        \n",
    "        runtime = sum([get_runtime(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True) for x in train_X_bounded])\n",
    "        runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        \n",
    "        val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "        row = [alpha.item(), beta.item(), lr_0.item(), n, i, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "        pet37_bo_df.loc[len(pet37_bo_df)] = row\n",
    "\n",
    "pet37_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7622.572840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.165683</td>\n",
       "      <td>0.882930</td>\n",
       "      <td>0.401487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>11848.482882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.271046</td>\n",
       "      <td>0.882930</td>\n",
       "      <td>0.401487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>370.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>15563.387040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.208767</td>\n",
       "      <td>0.882930</td>\n",
       "      <td>0.401487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>19318.812913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.161634</td>\n",
       "      <td>0.892498</td>\n",
       "      <td>0.366005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>370.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>23596.698935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.285752</td>\n",
       "      <td>0.892498</td>\n",
       "      <td>0.366005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>370.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>95031.721633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.155863</td>\n",
       "      <td>0.898210</td>\n",
       "      <td>0.345382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>370.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>98789.311465</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.163098</td>\n",
       "      <td>0.898210</td>\n",
       "      <td>0.345382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>370.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>102577.886484</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.227530</td>\n",
       "      <td>0.898210</td>\n",
       "      <td>0.345382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>370.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>106197.095139</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.149829</td>\n",
       "      <td>0.898210</td>\n",
       "      <td>0.345382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>370.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>109943.125661</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.898210</td>\n",
       "      <td>0.345382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0      n  n_iter  random_state        runtime  \\\n",
       "0   0.007589  0.000678  0.002389  370.0     0.0        1001.0    7622.572840   \n",
       "1   0.000001  0.000001  0.100000  370.0     1.0        1001.0   11848.482882   \n",
       "2   0.002364  0.001456  0.000670  370.0     2.0        1001.0   15563.387040   \n",
       "3   0.010000  0.000337  0.008134  370.0     3.0        1001.0   19318.812913   \n",
       "4   0.010000  0.000031  0.000408  370.0     4.0        1001.0   23596.698935   \n",
       "..       ...       ...       ...    ...     ...           ...            ...   \n",
       "95  0.000001  0.000026  0.002887  370.0    23.0        1001.0   95031.721633   \n",
       "96  0.010000  0.000021  0.003342  370.0    24.0        1001.0   98789.311465   \n",
       "97  0.000001  0.010000  0.001780  370.0    25.0        1001.0  102577.886484   \n",
       "98  0.010000  0.000031  0.021537  370.0    26.0        1001.0  106197.095139   \n",
       "99  0.010000  0.000097  0.001762  370.0    27.0        1001.0  109943.125661   \n",
       "\n",
       "    seed   val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0  0.932432  0.165683  0.882930  0.401487  \n",
       "1    0.0  0.891892  0.271046  0.882930  0.401487  \n",
       "2    0.0  0.959459  0.208767  0.882930  0.401487  \n",
       "3    0.0  0.959459  0.161634  0.892498  0.366005  \n",
       "4    0.0  0.972973  0.285752  0.892498  0.366005  \n",
       "..   ...       ...       ...       ...       ...  \n",
       "95   2.0  0.932432  0.155863  0.898210  0.345382  \n",
       "96   2.0  0.945946  0.163098  0.898210  0.345382  \n",
       "97   2.0  0.945946  0.227530  0.898210  0.345382  \n",
       "98   2.0  0.945946  0.149829  0.898210  0.345382  \n",
       "99   2.0  0.918919  0.173667  0.898210  0.345382  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pet37_bo_df.to_csv(\"Pet-37_ConvNeXt-Tiny_BO.csv\", index=False)\n",
    "pet37_bo_df = pd.read_csv(\"Pet-37_ConvNeXt-Tiny_BO.csv\")\n",
    "pet37_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
