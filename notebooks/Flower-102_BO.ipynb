{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "import matplotlib.ticker as ticker\n",
    "# PyTorch\n",
    "import torch\n",
    "# GPyTorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "# BOTorch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def check_epochs(df, n, batch_size=128, steps=6000, drop_last=True):\n",
    "    num_batches = math.floor(n/batch_size) if drop_last else math.ceil(n/batch_size)\n",
    "    epochs = int(steps/num_batches)\n",
    "    return df.shape[0] == epochs\n",
    "\n",
    "def print_job(alpha, beta, dataset, dataset_dir, experiments_dir, lr_0, \n",
    "              method, model, model_arch, n, prior_dir, prior_type, random_state, \n",
    "              save, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        temp_df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "        n_train = n - int((1/5) * n) if tune else n\n",
    "        if check_epochs(temp_df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "            return\n",
    "\n",
    "    command = (\n",
    "        f\"python ../src/main_image_classifiers.py \"\n",
    "        f\"--alpha={alpha} \"\n",
    "        \"--batch_size=128 \"\n",
    "        f\"--beta={beta} \"\n",
    "        f\"--dataset=\\\"{dataset}\\\" \"\n",
    "        f\"--dataset_dir=\\\"{dataset_dir}\\\" \"\n",
    "        f\"--experiments_dir=\\\"{experiments_dir}\\\" \"\n",
    "        f\"--lr_0={lr_0} \"\n",
    "        f\"--method=\\\"{method}\\\" \"\n",
    "        f\"--model=\\\"{model}\\\" \"\n",
    "        f\"--model_arch=\\\"{model_arch}\\\" \"\n",
    "        f\"--model_name=\\\"{model_name}\\\" \"\n",
    "        f\"--n={n} \"\n",
    "        \"--num_workers=0 \"\n",
    "        f\"--prior_dir=\\\"{prior_dir}\\\" \"\n",
    "        f\"--prior_type=\\\"{prior_type}\\\" \"\n",
    "        f\"--random_state={random_state} \"\n",
    "        f\"{'--save' if save else ''}\"\n",
    "        f\"{'--tune' if tune else ''}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"    '{command}'\")\n",
    "    \n",
    "def get_runtime(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"train_sec/epoch\"].sum()\n",
    "\n",
    "def get_val_or_test_acc(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_acc\"].values[-1]\n",
    "    \n",
    "def get_val_or_test_nll(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return float(\"inf\")\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return float(\"inf\")\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_nll\"].values[-1]\n",
    "\n",
    "def get_candidate(train_X, train_Y, seed):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    gp = SingleTaskGP(\n",
    "        train_X=train_X,\n",
    "        train_Y=train_Y,\n",
    "        input_transform=Normalize(d=3),\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    logEI = LogExpectedImprovement(model=gp, best_f=train_Y.max())\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(3), torch.ones(3)]).to(torch.double)\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "      logEI, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    )\n",
    "    \n",
    "    return candidate.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE:\n",
    "\n",
    "# CIFAR-10 n_iters = 41 tuned\n",
    "# Flower-102 n_iters = 41 tuned\n",
    "# Pet-37 n_iters = 41 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 35 retrained\n",
    "# Flower-102 n_iters = 35 retrained\n",
    "# Pet-37 n_iters = 35 retrained\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# CIFAR-10 n_iters = 42 tuned\n",
    "# Flower-102 n_iters = 42 tuned\n",
    "# Pet-37 n_iters = 42 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 36 retrained\n",
    "# Flower-102 n_iters = 36 retrained\n",
    "# Pet-37 n_iters = 36 retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7108.617203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.944847</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.820326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>10784.787583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.488824</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.820326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14534.996344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.545155</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.820326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>18374.722632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813726</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.849457</td>\n",
       "      <td>0.762403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>510.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22179.254153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813726</td>\n",
       "      <td>0.927907</td>\n",
       "      <td>0.849457</td>\n",
       "      <td>0.762403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>510.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>93540.990056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.668450</td>\n",
       "      <td>0.892671</td>\n",
       "      <td>0.518188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>510.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>97861.830223</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.711648</td>\n",
       "      <td>0.892671</td>\n",
       "      <td>0.518188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>510.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>102166.745179</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.625879</td>\n",
       "      <td>0.893234</td>\n",
       "      <td>0.514453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>510.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>105892.779017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>1.124442</td>\n",
       "      <td>0.893234</td>\n",
       "      <td>0.514453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>510.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>109695.507296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.642036</td>\n",
       "      <td>0.893234</td>\n",
       "      <td>0.514453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0      n  n_iter  random_state        runtime  \\\n",
       "0   0.007589  0.000678  0.002389  510.0     0.0        1001.0    7108.617203   \n",
       "1   0.000001  0.000001  0.100000  510.0     1.0        1001.0   10784.787583   \n",
       "2   0.003448  0.001479  0.000639  510.0     2.0        1001.0   14534.996344   \n",
       "3   0.010000  0.000513  0.003804  510.0     3.0        1001.0   18374.722632   \n",
       "4   0.010000  0.003177  0.004515  510.0     4.0        1001.0   22179.254153   \n",
       "..       ...       ...       ...    ...     ...           ...            ...   \n",
       "95  0.000018  0.000001  0.020334  510.0    23.0        1001.0   93540.990056   \n",
       "96  0.000001  0.000001  0.017856  510.0    24.0        1001.0   97861.830223   \n",
       "97  0.000040  0.000001  0.022994  510.0    25.0        1001.0  102166.745179   \n",
       "98  0.010000  0.000001  0.001238  510.0    26.0        1001.0  105892.779017   \n",
       "99  0.000069  0.000001  0.026843  510.0    27.0        1001.0  109695.507296   \n",
       "\n",
       "    seed   val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0  0.794118  0.944847  0.832493  0.820326  \n",
       "1    0.0  0.666667  1.488824  0.832493  0.820326  \n",
       "2    0.0  0.764706  1.545155  0.832493  0.820326  \n",
       "3    0.0  0.813726  0.894170  0.849457  0.762403  \n",
       "4    0.0  0.813726  0.927907  0.849457  0.762403  \n",
       "..   ...       ...       ...       ...       ...  \n",
       "95   2.0  0.843137  0.668450  0.892671  0.518188  \n",
       "96   2.0  0.803922  0.711648  0.892671  0.518188  \n",
       "97   2.0  0.843137  0.625879  0.893234  0.514453  \n",
       "98   2.0  0.794118  1.124442  0.893234  0.514453  \n",
       "99   2.0  0.823529  0.642036  0.893234  0.514453  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"Flower-102\"\n",
    "dataset_dir = \"{home_dir}/Flower-102\"\n",
    "model = \"l2-sp\"\n",
    "method = \"MAP\"\n",
    "model_arch = \"ConvNeXt-Tiny\"\n",
    "ns = [510, 1020]\n",
    "prior_dir = \"{home_dir}/convnext_tiny_torchvision\"\n",
    "prior_type = \"convnext_tiny_torchvision\"\n",
    "random_states = [1001, 2001, 3001]\n",
    "retrained_experiments_dir = \"{home_dir}/data-emphasized-ELBo/experiments/retrained_Flower-102_ConvNeXt-Tiny_BO\"\n",
    "tuned_experiments_dir = \"{home_dir}/data-emphasized-ELBo/experiments/tuned_Flower-102_ConvNeXt-Tiny_BO\"\n",
    "\n",
    "n_iters = 35\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "bounds = torch.tensor([[-6, -6, -4], [-2, -2, -1]], dtype=torch.double)\n",
    "\n",
    "columns = [\"alpha\", \"beta\", \"lr_0\", \"n\", \"n_iter\", \"random_state\", \"runtime\", \"seed\", \"val_acc\", \"val_nll\", \"test_acc\", \"test_nll\"]\n",
    "flower102_bo_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for n, random_state, seed in itertools.product(ns, random_states, seeds):\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "\n",
    "    train_X = torch.rand(size=(1, 3,), generator=gen, dtype=torch.double)\n",
    "    train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "    \n",
    "    alpha, beta, lr_0 = 10**train_X_bounded[0]\n",
    "    print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "    train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "    \n",
    "    alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "    print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "    \n",
    "    runtime = get_runtime(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    \n",
    "    val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "    row = [alpha.item(), beta.item(), lr_0.item(), n, 0, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "    flower102_bo_df.loc[len(flower102_bo_df)] = row\n",
    "    \n",
    "    for i in range(1, n_iters+1):\n",
    "\n",
    "        candidate = get_candidate(train_X, train_Y, seed)\n",
    "        candidate_bounded = (bounds[1] - bounds[0]) * candidate + bounds[0]\n",
    "        train_X = torch.cat([train_X, candidate])\n",
    "        train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "                \n",
    "        alpha, beta, lr_0 = 10**candidate_bounded[0]        \n",
    "        print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "        train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "\n",
    "        alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "        #print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "        \n",
    "        runtime = sum([get_runtime(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True) for x in train_X_bounded])\n",
    "        runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        \n",
    "        val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "        row = [alpha.item(), beta.item(), lr_0.item(), n, i, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "        flower102_bo_df.loc[len(flower102_bo_df)] = row\n",
    "\n",
    "flower102_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7108.617203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.944847</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.820326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>10784.787583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.488824</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.820326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14534.996344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.545155</td>\n",
       "      <td>0.832493</td>\n",
       "      <td>0.820326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>18374.722632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813726</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.849457</td>\n",
       "      <td>0.762403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>510.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22179.254153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813726</td>\n",
       "      <td>0.927907</td>\n",
       "      <td>0.849457</td>\n",
       "      <td>0.762403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>510.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>93540.990056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.668450</td>\n",
       "      <td>0.892671</td>\n",
       "      <td>0.518188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>510.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>97861.830223</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.711648</td>\n",
       "      <td>0.892671</td>\n",
       "      <td>0.518188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>510.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>102166.745179</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.625879</td>\n",
       "      <td>0.893234</td>\n",
       "      <td>0.514453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>510.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>105892.779017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>1.124442</td>\n",
       "      <td>0.893234</td>\n",
       "      <td>0.514453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>510.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>109695.507296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.642036</td>\n",
       "      <td>0.893234</td>\n",
       "      <td>0.514453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0      n  n_iter  random_state        runtime  \\\n",
       "0   0.007589  0.000678  0.002389  510.0     0.0        1001.0    7108.617203   \n",
       "1   0.000001  0.000001  0.100000  510.0     1.0        1001.0   10784.787583   \n",
       "2   0.003448  0.001479  0.000639  510.0     2.0        1001.0   14534.996344   \n",
       "3   0.010000  0.000513  0.003804  510.0     3.0        1001.0   18374.722632   \n",
       "4   0.010000  0.003177  0.004515  510.0     4.0        1001.0   22179.254153   \n",
       "..       ...       ...       ...    ...     ...           ...            ...   \n",
       "95  0.000018  0.000001  0.020334  510.0    23.0        1001.0   93540.990056   \n",
       "96  0.000001  0.000001  0.017856  510.0    24.0        1001.0   97861.830223   \n",
       "97  0.000040  0.000001  0.022994  510.0    25.0        1001.0  102166.745179   \n",
       "98  0.010000  0.000001  0.001238  510.0    26.0        1001.0  105892.779017   \n",
       "99  0.000069  0.000001  0.026843  510.0    27.0        1001.0  109695.507296   \n",
       "\n",
       "    seed   val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0  0.794118  0.944847  0.832493  0.820326  \n",
       "1    0.0  0.666667  1.488824  0.832493  0.820326  \n",
       "2    0.0  0.764706  1.545155  0.832493  0.820326  \n",
       "3    0.0  0.813726  0.894170  0.849457  0.762403  \n",
       "4    0.0  0.813726  0.927907  0.849457  0.762403  \n",
       "..   ...       ...       ...       ...       ...  \n",
       "95   2.0  0.843137  0.668450  0.892671  0.518188  \n",
       "96   2.0  0.803922  0.711648  0.892671  0.518188  \n",
       "97   2.0  0.843137  0.625879  0.893234  0.514453  \n",
       "98   2.0  0.794118  1.124442  0.893234  0.514453  \n",
       "99   2.0  0.823529  0.642036  0.893234  0.514453  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flower102_bo_df.to_csv(\"Flower-102_ConvNeXt-Tiny_BO.csv\", index=False)\n",
    "flower102_bo_df = pd.read_csv(\"Flower-102_ConvNeXt-Tiny_BO.csv\")\n",
    "flower102_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
