{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Importing our custom module(s)\n",
    "import losses\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "n = 1000\n",
    "tune = False\n",
    "random_state = 1001\n",
    "augmented_train_dataset, train_dataset, val_or_test_dataset = utils.get_cifar10_datasets(dataset_directory, n, tune, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 0\n",
    "augmented_train_loader = torch.utils.data.DataLoader(augmented_train_dataset, batch_size=min(batch_size, len(augmented_train_dataset)), shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=min(batch_size, len(train_dataset)), num_workers=num_workers)\n",
    "val_or_test_loader = torch.utils.data.DataLoader(val_or_test_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "bb_loc = torch.load('/cluster/tufts/hugheslab/eharve06/resnet50_torchvision/resnet50_torchvision_mean.pt', map_location=torch.device('cpu')).to(device)\n",
    "criterion = losses.ERMLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927000761032104\n",
      "0.8442955075263979\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI/l2-sp_kappa=23528.522_lr_0=0.01_n=1000_random_state=1001.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "checkpoint = {key.replace('.layer', ''): value for key, value in checkpoint.items()}\n",
    "\n",
    "sigma_param = checkpoint['sigma_param']\n",
    "\n",
    "keys_to_remove = [key for key in checkpoint if key.endswith('sigma_param')]\n",
    "for key in keys_to_remove:\n",
    "    checkpoint.pop(key, None)\n",
    "    \n",
    "for key in checkpoint:\n",
    "    if checkpoint[key].requires_grad:\n",
    "        checkpoint[key] += torch.nn.functional.softplus(sigma_param) * torch.randn_like(checkpoint[key])\n",
    "\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "val_or_test_metrics = utils.evaluate(model, criterion, val_or_test_loader, num_classes=num_classes)\n",
    "print(val_or_test_metrics['acc'])\n",
    "print(val_or_test_metrics['nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8985000252723694\n",
      "0.8001144462585451\n"
     ]
    }
   ],
   "source": [
    "utils.bn_update(model, train_loader)\n",
    "val_or_test_metrics = utils.evaluate(model, criterion, val_or_test_loader, num_classes=num_classes)\n",
    "print(val_or_test_metrics['acc'])\n",
    "print(val_or_test_metrics['nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl-transfer-learning",
   "language": "python",
   "name": "bdl-transfer-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
