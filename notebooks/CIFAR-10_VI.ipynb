{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_epochs(df, n, batch_size=128, steps=6000):\n",
    "    num_batches = math.floor(n/batch_size)\n",
    "    epochs = int(steps/num_batches)\n",
    "    if df.shape[0] == epochs:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "criterion = 'l2-zero'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "count = -1\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        if not check_epochs(temp_df, n, batch_size=min(128, n), steps=6000):\n",
    "            count += 1\n",
    "            print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --random_state={random_state} --save\"')\n",
    "    else:\n",
    "        count += 1\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --random_state={random_state} --save\"')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.1 --model_name='l2-sp_kappa=235285.22_lr_0=0.1_n=100_random_state=1001' --n=100 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.1 --model_name='l2-sp_kappa=235285.22_lr_0=0.1_n=100_random_state=2001' --n=100 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.1 --model_name='l2-sp_kappa=235285.22_lr_0=0.1_n=100_random_state=3001' --n=100 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.1 --model_name='l2-sp_kappa=23528.522_lr_0=0.1_n=1000_random_state=1001' --n=1000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.1 --model_name='l2-sp_kappa=23528.522_lr_0=0.1_n=1000_random_state=2001' --n=1000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.1 --model_name='l2-sp_kappa=23528.522_lr_0=0.1_n=1000_random_state=3001' --n=1000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.1 --model_name='l2-sp_kappa=2352.8522_lr_0=0.1_n=10000_random_state=1001' --n=10000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.1 --model_name='l2-sp_kappa=2352.8522_lr_0=0.1_n=10000_random_state=2001' --n=10000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.1 --model_name='l2-sp_kappa=2352.8522_lr_0=0.1_n=10000_random_state=3001' --n=10000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.1 --model_name='l2-sp_kappa=470.57044_lr_0=0.1_n=50000_random_state=1001' --n=50000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.1 --model_name='l2-sp_kappa=470.57044_lr_0=0.1_n=50000_random_state=2001' --n=50000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.1 --model_name='l2-sp_kappa=470.57044_lr_0=0.1_n=50000_random_state=3001' --n=50000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.01 --model_name='l2-sp_kappa=235285.22_lr_0=0.01_n=100_random_state=1001' --n=100 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.01 --model_name='l2-sp_kappa=235285.22_lr_0=0.01_n=100_random_state=2001' --n=100 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.01 --model_name='l2-sp_kappa=235285.22_lr_0=0.01_n=100_random_state=3001' --n=100 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.01 --model_name='l2-sp_kappa=23528.522_lr_0=0.01_n=1000_random_state=1001' --n=1000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.01 --model_name='l2-sp_kappa=23528.522_lr_0=0.01_n=1000_random_state=2001' --n=1000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.01 --model_name='l2-sp_kappa=23528.522_lr_0=0.01_n=1000_random_state=3001' --n=1000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.01 --model_name='l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random_state=1001' --n=10000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.01 --model_name='l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random_state=2001' --n=10000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.01 --model_name='l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random_state=3001' --n=10000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.01 --model_name='l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random_state=1001' --n=50000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.01 --model_name='l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random_state=2001' --n=50000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.01 --model_name='l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random_state=3001' --n=50000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.001 --model_name='l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_state=1001' --n=100 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.001 --model_name='l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_state=2001' --n=100 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.001 --model_name='l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_state=3001' --n=100 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.001 --model_name='l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random_state=1001' --n=1000 --num_workers=0 --random_state=1001 --save\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.001 --model_name='l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random_state=2001' --n=1000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.001 --model_name='l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random_state=3001' --n=1000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.001 --model_name='l2-sp_kappa=2352.8522_lr_0=0.001_n=10000_random_state=1001' --n=10000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.001 --model_name='l2-sp_kappa=2352.8522_lr_0=0.001_n=10000_random_state=2001' --n=10000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.001 --model_name='l2-sp_kappa=2352.8522_lr_0=0.001_n=10000_random_state=3001' --n=10000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.001 --model_name='l2-sp_kappa=470.57044_lr_0=0.001_n=50000_random_state=1001' --n=50000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.001 --model_name='l2-sp_kappa=470.57044_lr_0=0.001_n=50000_random_state=2001' --n=50000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.001 --model_name='l2-sp_kappa=470.57044_lr_0=0.001_n=50000_random_state=3001' --n=50000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.0001 --model_name='l2-sp_kappa=235285.22_lr_0=0.0001_n=100_random_state=1001' --n=100 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.0001 --model_name='l2-sp_kappa=235285.22_lr_0=0.0001_n=100_random_state=2001' --n=100 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=235285.22 --lr_0=0.0001 --model_name='l2-sp_kappa=235285.22_lr_0=0.0001_n=100_random_state=3001' --n=100 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.0001 --model_name='l2-sp_kappa=23528.522_lr_0=0.0001_n=1000_random_state=1001' --n=1000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.0001 --model_name='l2-sp_kappa=23528.522_lr_0=0.0001_n=1000_random_state=2001' --n=1000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=23528.522 --lr_0=0.0001 --model_name='l2-sp_kappa=23528.522_lr_0=0.0001_n=1000_random_state=3001' --n=1000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.0001 --model_name='l2-sp_kappa=2352.8522_lr_0=0.0001_n=10000_random_state=1001' --n=10000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.0001 --model_name='l2-sp_kappa=2352.8522_lr_0=0.0001_n=10000_random_state=2001' --n=10000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=2352.8522 --lr_0=0.0001 --model_name='l2-sp_kappa=2352.8522_lr_0=0.0001_n=10000_random_state=3001' --n=10000 --num_workers=0 --random_state=3001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.0001 --model_name='l2-sp_kappa=470.57044_lr_0=0.0001_n=50000_random_state=1001' --n=50000 --num_workers=0 --random_state=1001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.0001 --model_name='l2-sp_kappa=470.57044_lr_0=0.0001_n=50000_random_state=2001' --n=50000 --num_workers=0 --random_state=2001 --save\"\n",
      "    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion='l2-sp' --dataset_directory='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --ELBo --experiments_directory='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000' --kappa=470.57044 --lr_0=0.0001 --model_name='l2-sp_kappa=470.57044_lr_0=0.0001_n=50000_random_state=3001' --n=50000 --num_workers=0 --random_state=3001 --save\"\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "criterion = 'l2-sp'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI_iters=30000'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "count = -1\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        if not check_epochs(temp_df, n, batch_size=min(128, n), steps=6000):\n",
    "            count += 1\n",
    "            print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --random_state={random_state} --save\"')\n",
    "    else:\n",
    "        count += 1\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --random_state={random_state} --save\"')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "criterion = 'ptyl'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_SSL_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "prior_directory = '/cluster/tufts/hugheslab/eharve06/resnet50_ssl_prior'\n",
    "prior_type = 'resnet50_ssl_prior'\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "count = -1\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        if not check_epochs(temp_df, n, batch_size=min(128, n), steps=6000):\n",
    "            count += 1\n",
    "            print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --prior_directory=\\'{prior_directory}\\' --prior_type=\\'{prior_type}\\' --random_state={random_state} --save\"')\n",
    "    else:\n",
    "        count += 1\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --prior_directory=\\'{prior_directory}\\' --prior_type=\\'{prior_type}\\' --random_state={random_state} --save\"')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "criterion = 'ptyl'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "count = -1\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        if not check_epochs(temp_df, n, batch_size=min(128, n), steps=6000):\n",
    "            count += 1\n",
    "            print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --random_state={random_state} --save\"')\n",
    "    else:\n",
    "        count += 1\n",
    "        print(f'    \"python ../src/main_CIFAR-10.py --batch_size=128 --criterion=\\'{criterion}\\' --dataset_directory=\\'{dataset_directory}\\' --ELBo --experiments_directory=\\'{experiments_directory}\\' --kappa={d/n} --lr_0={lr_0} --model_name=\\'{model_name}\\' --n={n} --num_workers=0 --random_state={random_state} --save\"')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=235285.22_lr_0=0.001_n=100_rando...</td>\n",
       "      <td>100</td>\n",
       "      <td>1001</td>\n",
       "      <td>7.987484e+07</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>2.735646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=235285.22_lr_0=0.001_n=100_rando...</td>\n",
       "      <td>100</td>\n",
       "      <td>2001</td>\n",
       "      <td>7.280507e+07</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>2.880208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=235285.22_lr_0=0.001_n=100_rando...</td>\n",
       "      <td>100</td>\n",
       "      <td>3001</td>\n",
       "      <td>6.520396e+07</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>2.499837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=23528.522_lr_0=0.001_n=1000_rand...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4.998312e+07</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>0.502714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=23528.522_lr_0=0.001_n=1000_rand...</td>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4.782618e+07</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.533140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=23528.522_lr_0=0.001_n=1000_rand...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3001</td>\n",
       "      <td>4.705157e+07</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.550950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=2352.8522_lr_0=0.1_n=10000_rando...</td>\n",
       "      <td>10000</td>\n",
       "      <td>1001</td>\n",
       "      <td>4.266812e+07</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.693176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=2352.8522_lr_0=0.001_n=10000_ran...</td>\n",
       "      <td>10000</td>\n",
       "      <td>2001</td>\n",
       "      <td>4.277857e+07</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.288749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=2352.8522_lr_0=0.001_n=10000_ran...</td>\n",
       "      <td>10000</td>\n",
       "      <td>3001</td>\n",
       "      <td>4.300660e+07</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rando...</td>\n",
       "      <td>50000</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.442958e+07</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.274340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rando...</td>\n",
       "      <td>50000</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.337915e+07</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.313323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rando...</td>\n",
       "      <td>50000</td>\n",
       "      <td>3001</td>\n",
       "      <td>3.459465e+07</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.295894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                         model_name      n  \\\n",
       "24   l2-zero  l2-zero_kappa=235285.22_lr_0=0.001_n=100_rando...    100   \n",
       "25   l2-zero  l2-zero_kappa=235285.22_lr_0=0.001_n=100_rando...    100   \n",
       "26   l2-zero  l2-zero_kappa=235285.22_lr_0=0.001_n=100_rando...    100   \n",
       "27   l2-zero  l2-zero_kappa=23528.522_lr_0=0.001_n=1000_rand...   1000   \n",
       "28   l2-zero  l2-zero_kappa=23528.522_lr_0=0.001_n=1000_rand...   1000   \n",
       "29   l2-zero  l2-zero_kappa=23528.522_lr_0=0.001_n=1000_rand...   1000   \n",
       "6    l2-zero  l2-zero_kappa=2352.8522_lr_0=0.1_n=10000_rando...  10000   \n",
       "31   l2-zero  l2-zero_kappa=2352.8522_lr_0=0.001_n=10000_ran...  10000   \n",
       "32   l2-zero  l2-zero_kappa=2352.8522_lr_0=0.001_n=10000_ran...  10000   \n",
       "9    l2-zero  l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rando...  50000   \n",
       "10   l2-zero  l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rando...  50000   \n",
       "11   l2-zero  l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rando...  50000   \n",
       "\n",
       "    random_state    train_loss  test_acc  test_nll  \n",
       "24          1001  7.987484e+07    0.6247  2.735646  \n",
       "25          2001  7.280507e+07    0.6071  2.880208  \n",
       "26          3001  6.520396e+07    0.6330  2.499837  \n",
       "27          1001  4.998312e+07    0.8765  0.502714  \n",
       "28          2001  4.782618e+07    0.8737  0.533140  \n",
       "29          3001  4.705157e+07    0.8692  0.550950  \n",
       "6           1001  4.266812e+07    0.9025  0.693176  \n",
       "31          2001  4.277857e+07    0.9088  0.288749  \n",
       "32          3001  4.300660e+07    0.9160  0.260938  \n",
       "9           1001  3.442958e+07    0.9326  0.274340  \n",
       "10          2001  3.337915e+07    0.9269  0.313323  \n",
       "11          3001  3.459465e+07    0.9294  0.295894  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'l2-zero'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_loss', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_loss.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "    \n",
    "min_indices = retrained_df.groupby(['criterion', 'n', 'random_state'])['train_loss'].idxmin()\n",
    "retrained_df = retrained_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>100</td>\n",
       "      <td>(l2-zero_kappa=235285.22_lr_0=0.001_n=100_rand...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(79874842.4, 72805072.0, 65203962.0)</td>\n",
       "      <td>(0.6247000098228455, 0.6071000099182129, 0.632...</td>\n",
       "      <td>(2.7356458805084243, 2.88020813217163, 2.49983...</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>2.705230</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>2.499837</td>\n",
       "      <td>2.880208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1000</td>\n",
       "      <td>(l2-zero_kappa=23528.522_lr_0=0.001_n=1000_ran...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(49983119.6512, 47826175.47840001, 47051569.03...</td>\n",
       "      <td>(0.8764999508857727, 0.8737000226974487, 0.869...</td>\n",
       "      <td>(0.5027143522262574, 0.5331401852130888, 0.550...</td>\n",
       "      <td>0.873133</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>0.528935</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>0.502714</td>\n",
       "      <td>0.550950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>10000</td>\n",
       "      <td>(l2-zero_kappa=2352.8522_lr_0=0.1_n=10000_rand...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(42668122.14016, 42778572.83968, 43006599.5516...</td>\n",
       "      <td>(0.9025000333786012, 0.908799946308136, 0.9159...</td>\n",
       "      <td>(0.6931758224487305, 0.288748571395874, 0.2609...</td>\n",
       "      <td>0.909100</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.414287</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.260938</td>\n",
       "      <td>0.693176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>50000</td>\n",
       "      <td>(l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rand...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(34429582.60281599, 33379151.891328, 34594649....</td>\n",
       "      <td>(0.9326000213623048, 0.926900029182434, 0.9294...</td>\n",
       "      <td>(0.2743397240638733, 0.313322682571411, 0.2958...</td>\n",
       "      <td>0.929633</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.294519</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.274340</td>\n",
       "      <td>0.313323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n                                         model_name  \\\n",
       "0   l2-zero    100  (l2-zero_kappa=235285.22_lr_0=0.001_n=100_rand...   \n",
       "1   l2-zero   1000  (l2-zero_kappa=23528.522_lr_0=0.001_n=1000_ran...   \n",
       "2   l2-zero  10000  (l2-zero_kappa=2352.8522_lr_0=0.1_n=10000_rand...   \n",
       "3   l2-zero  50000  (l2-zero_kappa=470.57044_lr_0=0.1_n=50000_rand...   \n",
       "\n",
       "         random_state                                         train_loss  \\\n",
       "0  (1001, 2001, 3001)               (79874842.4, 72805072.0, 65203962.0)   \n",
       "1  (1001, 2001, 3001)  (49983119.6512, 47826175.47840001, 47051569.03...   \n",
       "2  (1001, 2001, 3001)  (42668122.14016, 42778572.83968, 43006599.5516...   \n",
       "3  (1001, 2001, 3001)  (34429582.60281599, 33379151.891328, 34594649....   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.6247000098228455, 0.6071000099182129, 0.632...   \n",
       "1  (0.8764999508857727, 0.8737000226974487, 0.869...   \n",
       "2  (0.9025000333786012, 0.908799946308136, 0.9159...   \n",
       "3  (0.9326000213623048, 0.926900029182434, 0.9294...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (2.7356458805084243, 2.88020813217163, 2.49983...       0.621600   \n",
       "1  (0.5027143522262574, 0.5331401852130888, 0.550...       0.873133   \n",
       "2  (0.6931758224487305, 0.288748571395874, 0.2609...       0.909100   \n",
       "3  (0.2743397240638733, 0.313322682571411, 0.2958...       0.929633   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.010798        0.6071        0.6330       2.705230      0.156768   \n",
       "1      0.003007        0.8692        0.8765       0.528935      0.019915   \n",
       "2      0.005515        0.9025        0.9160       0.414287      0.197531   \n",
       "3      0.002333        0.9269        0.9326       0.294519      0.015944   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      2.499837      2.880208  \n",
       "1      0.502714      0.550950  \n",
       "2      0.260938      0.693176  \n",
       "3      0.274340      0.313323  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>100</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.873133</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.8765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.909100</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.9160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.929633</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0   l2-zero    100       0.621600        0.6071        0.6330\n",
       "1   l2-zero   1000       0.873133        0.8692        0.8765\n",
       "2   l2-zero  10000       0.909100        0.9025        0.9160\n",
       "3   l2-zero  50000       0.929633        0.9269        0.9326"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>100</td>\n",
       "      <td>2.705230</td>\n",
       "      <td>2.499837</td>\n",
       "      <td>2.880208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.528935</td>\n",
       "      <td>0.502714</td>\n",
       "      <td>0.550950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.414287</td>\n",
       "      <td>0.260938</td>\n",
       "      <td>0.693176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-zero</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.294519</td>\n",
       "      <td>0.274340</td>\n",
       "      <td>0.313323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0   l2-zero    100       2.705230      2.499837      2.880208\n",
       "1   l2-zero   1000       0.528935      0.502714      0.550950\n",
       "2   l2-zero  10000       0.414287      0.260938      0.693176\n",
       "3   l2-zero  50000       0.294519      0.274340      0.313323"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_state=1001'\n",
      " 'l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_state=2001'\n",
      " 'l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_state=3001'\n",
      " 'l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random_state=1001'\n",
      " 'l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random_state=2001'\n",
      " 'l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random_state=3001'\n",
      " 'l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random_state=1001'\n",
      " 'l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random_state=2001'\n",
      " 'l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random_state=3001'\n",
      " 'l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random_state=1001'\n",
      " 'l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random_state=2001'\n",
      " 'l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random_state=3001']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_...</td>\n",
       "      <td>100</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.241041e+05</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>0.959640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_...</td>\n",
       "      <td>100</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.450325e+05</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>1.191830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_...</td>\n",
       "      <td>100</td>\n",
       "      <td>3001</td>\n",
       "      <td>5.003831e+05</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.959388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001</td>\n",
       "      <td>8.081569e+05</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.388796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random...</td>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.745489e+05</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.393274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3001</td>\n",
       "      <td>6.726705e+05</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.415737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random...</td>\n",
       "      <td>10000</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.185813e+06</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.265158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random...</td>\n",
       "      <td>10000</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.204540e+06</td>\n",
       "      <td>0.9486</td>\n",
       "      <td>0.271640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random...</td>\n",
       "      <td>10000</td>\n",
       "      <td>3001</td>\n",
       "      <td>3.308029e+06</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.251166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random...</td>\n",
       "      <td>50000</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.335702e+06</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random...</td>\n",
       "      <td>50000</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.317316e+06</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.117079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random...</td>\n",
       "      <td>50000</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.376302e+06</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.117263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                         model_name      n  \\\n",
       "24     l2-sp  l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_...    100   \n",
       "25     l2-sp  l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_...    100   \n",
       "26     l2-sp  l2-sp_kappa=235285.22_lr_0=0.001_n=100_random_...    100   \n",
       "27     l2-sp  l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random...   1000   \n",
       "28     l2-sp  l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random...   1000   \n",
       "29     l2-sp  l2-sp_kappa=23528.522_lr_0=0.001_n=1000_random...   1000   \n",
       "18     l2-sp  l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random...  10000   \n",
       "19     l2-sp  l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random...  10000   \n",
       "20     l2-sp  l2-sp_kappa=2352.8522_lr_0=0.01_n=10000_random...  10000   \n",
       "21     l2-sp  l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random...  50000   \n",
       "22     l2-sp  l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random...  50000   \n",
       "23     l2-sp  l2-sp_kappa=470.57044_lr_0=0.01_n=50000_random...  50000   \n",
       "\n",
       "    random_state    train_loss  test_acc  test_nll  \n",
       "24          1001  1.241041e+05    0.7014  0.959640  \n",
       "25          2001  8.450325e+05    0.6862  1.191830  \n",
       "26          3001  5.003831e+05    0.7308  0.959388  \n",
       "27          1001  8.081569e+05    0.8739  0.388796  \n",
       "28          2001  8.745489e+05    0.8741  0.393274  \n",
       "29          3001  6.726705e+05    0.8707  0.415737  \n",
       "18          1001  3.185813e+06    0.9520  0.265158  \n",
       "19          2001  3.204540e+06    0.9486  0.271640  \n",
       "20          3001  3.308029e+06    0.9518  0.251166  \n",
       "21          1001  1.335702e+06    0.9668  0.118539  \n",
       "22          2001  1.317316e+06    0.9680  0.117079  \n",
       "23          3001  1.376302e+06    0.9684  0.117263  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'l2-sp'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_loss', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_loss.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "    \n",
    "min_indices = retrained_df.groupby(['criterion', 'n', 'random_state'])['train_loss'].idxmin()\n",
    "retrained_df = retrained_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>100</td>\n",
       "      <td>(l2-sp_kappa=235285.22_lr_0=0.0001_n=100_rando...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(1000671.34375, 321581.509375, 305993.45)</td>\n",
       "      <td>(0.6935999989509583, 0.6574000120162964, 0.705...</td>\n",
       "      <td>(0.9195248167037964, 1.0414291486740113, 0.890...</td>\n",
       "      <td>0.685433</td>\n",
       "      <td>0.020390</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.950645</td>\n",
       "      <td>0.065243</td>\n",
       "      <td>0.890980</td>\n",
       "      <td>1.041429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1000</td>\n",
       "      <td>(l2-sp_kappa=23528.522_lr_0=0.0001_n=1000_rand...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(5425212.2048, 5719436.2488, 5499672.326)</td>\n",
       "      <td>(0.8588999509811401, 0.8641000390052795, 0.857...</td>\n",
       "      <td>(0.4360437826156616, 0.4391814342975615, 0.455...</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.443502</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.436044</td>\n",
       "      <td>0.455282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>10000</td>\n",
       "      <td>(l2-sp_kappa=2352.8522_lr_0=0.001_n=10000_rand...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(1017153.4209, 1013934.7530725, 1010654.1455675)</td>\n",
       "      <td>(0.942300021648407, 0.9427000880241394, 0.9422...</td>\n",
       "      <td>(0.2511401765346527, 0.2483040474891663, 0.244...</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.244762</td>\n",
       "      <td>0.251140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>50000</td>\n",
       "      <td>(l2-sp_kappa=470.57044_lr_0=0.001_n=50000_rand...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(1276079.6269600005, 1261451.906556, 1254158.4...</td>\n",
       "      <td>(0.960099995136261, 0.960499942302704, 0.95919...</td>\n",
       "      <td>(0.1259697262763977, 0.1252013417005539, 0.126...</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.125769</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.125201</td>\n",
       "      <td>0.126137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n                                         model_name  \\\n",
       "0     l2-sp    100  (l2-sp_kappa=235285.22_lr_0=0.0001_n=100_rando...   \n",
       "1     l2-sp   1000  (l2-sp_kappa=23528.522_lr_0=0.0001_n=1000_rand...   \n",
       "2     l2-sp  10000  (l2-sp_kappa=2352.8522_lr_0=0.001_n=10000_rand...   \n",
       "3     l2-sp  50000  (l2-sp_kappa=470.57044_lr_0=0.001_n=50000_rand...   \n",
       "\n",
       "         random_state                                         train_loss  \\\n",
       "0  (1001, 2001, 3001)          (1000671.34375, 321581.509375, 305993.45)   \n",
       "1  (1001, 2001, 3001)          (5425212.2048, 5719436.2488, 5499672.326)   \n",
       "2  (1001, 2001, 3001)   (1017153.4209, 1013934.7530725, 1010654.1455675)   \n",
       "3  (1001, 2001, 3001)  (1276079.6269600005, 1261451.906556, 1254158.4...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.6935999989509583, 0.6574000120162964, 0.705...   \n",
       "1  (0.8588999509811401, 0.8641000390052795, 0.857...   \n",
       "2  (0.942300021648407, 0.9427000880241394, 0.9422...   \n",
       "3  (0.960099995136261, 0.960499942302704, 0.95919...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (0.9195248167037964, 1.0414291486740113, 0.890...       0.685433   \n",
       "1  (0.4360437826156616, 0.4391814342975615, 0.455...       0.860200   \n",
       "2  (0.2511401765346527, 0.2483040474891663, 0.244...       0.942400   \n",
       "3  (0.1259697262763977, 0.1252013417005539, 0.126...       0.959933   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.020390        0.6574        0.7053       0.950645      0.065243   \n",
       "1      0.002808        0.8576        0.8641       0.443502      0.008427   \n",
       "2      0.000216        0.9422        0.9427       0.248069      0.002609   \n",
       "3      0.000544        0.9592        0.9605       0.125769      0.000407   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      0.890980      1.041429  \n",
       "1      0.436044      0.455282  \n",
       "2      0.244762      0.251140  \n",
       "3      0.125201      0.126137  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>100</td>\n",
       "      <td>0.685433</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.7053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.8641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0     l2-sp    100       0.685433        0.6574        0.7053\n",
       "1     l2-sp   1000       0.860200        0.8576        0.8641\n",
       "2     l2-sp  10000       0.942400        0.9422        0.9427\n",
       "3     l2-sp  50000       0.959933        0.9592        0.9605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>100</td>\n",
       "      <td>0.950645</td>\n",
       "      <td>0.890980</td>\n",
       "      <td>1.041429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.443502</td>\n",
       "      <td>0.436044</td>\n",
       "      <td>0.455282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.244762</td>\n",
       "      <td>0.251140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2-sp</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.125769</td>\n",
       "      <td>0.125201</td>\n",
       "      <td>0.126137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0     l2-sp    100       0.950645      0.890980      1.041429\n",
       "1     l2-sp   1000       0.443502      0.436044      0.455282\n",
       "2     l2-sp  10000       0.248069      0.244762      0.251140\n",
       "3     l2-sp  50000       0.125769      0.125201      0.126137"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=235285.22_lr_0=0.0001_n=100_random_...</td>\n",
       "      <td>100</td>\n",
       "      <td>1001</td>\n",
       "      <td>2.592479e+07</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>1.551445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=235285.22_lr_0=0.0001_n=100_random_...</td>\n",
       "      <td>100</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.472794e+07</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>1.507268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=235285.22_lr_0=0.0001_n=100_random_...</td>\n",
       "      <td>100</td>\n",
       "      <td>3001</td>\n",
       "      <td>2.250617e+07</td>\n",
       "      <td>0.5953</td>\n",
       "      <td>1.463025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.597296e+06</td>\n",
       "      <td>0.7814</td>\n",
       "      <td>0.763501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.431025e+06</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.787477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.438243e+06</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.782926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=2352.8522_lr_0=0.001_n=10000_random...</td>\n",
       "      <td>10000</td>\n",
       "      <td>1001</td>\n",
       "      <td>6.385574e+06</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.307471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=2352.8522_lr_0=0.001_n=10000_random...</td>\n",
       "      <td>10000</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.317718e+06</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.291742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=2352.8522_lr_0=0.001_n=10000_random...</td>\n",
       "      <td>10000</td>\n",
       "      <td>3001</td>\n",
       "      <td>5.856593e+06</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.285636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...</td>\n",
       "      <td>50000</td>\n",
       "      <td>1001</td>\n",
       "      <td>6.872749e+06</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.116459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...</td>\n",
       "      <td>50000</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.687714e+06</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...</td>\n",
       "      <td>50000</td>\n",
       "      <td>3001</td>\n",
       "      <td>6.412031e+06</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.118628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                         model_name      n  \\\n",
       "36      ptyl  ptyl_kappa=235285.22_lr_0=0.0001_n=100_random_...    100   \n",
       "37      ptyl  ptyl_kappa=235285.22_lr_0=0.0001_n=100_random_...    100   \n",
       "38      ptyl  ptyl_kappa=235285.22_lr_0=0.0001_n=100_random_...    100   \n",
       "27      ptyl  ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...   1000   \n",
       "28      ptyl  ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...   1000   \n",
       "29      ptyl  ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...   1000   \n",
       "30      ptyl  ptyl_kappa=2352.8522_lr_0=0.001_n=10000_random...  10000   \n",
       "31      ptyl  ptyl_kappa=2352.8522_lr_0=0.001_n=10000_random...  10000   \n",
       "32      ptyl  ptyl_kappa=2352.8522_lr_0=0.001_n=10000_random...  10000   \n",
       "21      ptyl  ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...  50000   \n",
       "22      ptyl  ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...  50000   \n",
       "23      ptyl  ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...  50000   \n",
       "\n",
       "    random_state    train_loss  test_acc  test_nll  \n",
       "36          1001  2.592479e+07    0.6050  1.551445  \n",
       "37          2001  2.472794e+07    0.6070  1.507268  \n",
       "38          3001  2.250617e+07    0.5953  1.463025  \n",
       "27          1001  1.597296e+06    0.7814  0.763501  \n",
       "28          2001  1.431025e+06    0.7754  0.787477  \n",
       "29          3001  1.438243e+06    0.7876  0.782926  \n",
       "30          1001  6.385574e+06    0.9029  0.307471  \n",
       "31          2001  6.317718e+06    0.9068  0.291742  \n",
       "32          3001  5.856593e+06    0.9075  0.285636  \n",
       "21          1001  6.872749e+06    0.9670  0.116459  \n",
       "22          2001  6.687714e+06    0.9673  0.114500  \n",
       "23          3001  6.412031e+06    0.9661  0.118628  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'ptyl'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_SSL_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_loss', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_loss.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "    \n",
    "min_indices = retrained_df.groupby(['criterion', 'n', 'random_state'])['train_loss'].idxmin()\n",
    "retrained_df = retrained_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>100</td>\n",
       "      <td>(ptyl_kappa=235285.22_lr_0=0.0001_n=100_random...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(25924794.0, 24727941.2, 22506166.0)</td>\n",
       "      <td>(0.6050000190734863, 0.6069999933242798, 0.595...</td>\n",
       "      <td>(1.5514447090148926, 1.5072678478240962, 1.463...</td>\n",
       "      <td>0.602433</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.5953</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>1.507246</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>1.463025</td>\n",
       "      <td>1.551445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>1000</td>\n",
       "      <td>(ptyl_kappa=23528.522_lr_0=0.001_n=1000_random...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(1597295.64135, 1431024.79685, 1438242.6671)</td>\n",
       "      <td>(0.7814000248908997, 0.7754001021385193, 0.787...</td>\n",
       "      <td>(0.7635006882667545, 0.7874768589019774, 0.782...</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.777968</td>\n",
       "      <td>0.010397</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.787477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>10000</td>\n",
       "      <td>(ptyl_kappa=2352.8522_lr_0=0.001_n=10000_rando...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(6385573.60036, 6317717.84568, 5856592.630039999)</td>\n",
       "      <td>(0.902899980545044, 0.9067999720573424, 0.9074...</td>\n",
       "      <td>(0.3074707009315491, 0.2917423649787903, 0.285...</td>\n",
       "      <td>0.905733</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.294950</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.307471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>50000</td>\n",
       "      <td>(ptyl_kappa=470.57044_lr_0=0.01_n=50000_random...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(6872749.156728001, 6687714.023768, 6412031.04...</td>\n",
       "      <td>(0.9670000076293944, 0.9672999978065492, 0.966...</td>\n",
       "      <td>(0.1164585856437682, 0.1145001266479492, 0.118...</td>\n",
       "      <td>0.966800</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.116529</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.118628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n                                         model_name  \\\n",
       "0      ptyl    100  (ptyl_kappa=235285.22_lr_0=0.0001_n=100_random...   \n",
       "1      ptyl   1000  (ptyl_kappa=23528.522_lr_0=0.001_n=1000_random...   \n",
       "2      ptyl  10000  (ptyl_kappa=2352.8522_lr_0=0.001_n=10000_rando...   \n",
       "3      ptyl  50000  (ptyl_kappa=470.57044_lr_0=0.01_n=50000_random...   \n",
       "\n",
       "         random_state                                         train_loss  \\\n",
       "0  (1001, 2001, 3001)               (25924794.0, 24727941.2, 22506166.0)   \n",
       "1  (1001, 2001, 3001)       (1597295.64135, 1431024.79685, 1438242.6671)   \n",
       "2  (1001, 2001, 3001)  (6385573.60036, 6317717.84568, 5856592.630039999)   \n",
       "3  (1001, 2001, 3001)  (6872749.156728001, 6687714.023768, 6412031.04...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.6050000190734863, 0.6069999933242798, 0.595...   \n",
       "1  (0.7814000248908997, 0.7754001021385193, 0.787...   \n",
       "2  (0.902899980545044, 0.9067999720573424, 0.9074...   \n",
       "3  (0.9670000076293944, 0.9672999978065492, 0.966...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (1.5514447090148926, 1.5072678478240962, 1.463...       0.602433   \n",
       "1  (0.7635006882667545, 0.7874768589019774, 0.782...       0.781467   \n",
       "2  (0.3074707009315491, 0.2917423649787903, 0.285...       0.905733   \n",
       "3  (0.1164585856437682, 0.1145001266479492, 0.118...       0.966800   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.005110        0.5953        0.6070       1.507246      0.036097   \n",
       "1      0.004981        0.7754        0.7876       0.777968      0.010397   \n",
       "2      0.002024        0.9029        0.9075       0.294950      0.009198   \n",
       "3      0.000510        0.9661        0.9673       0.116529      0.001686   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      1.463025      1.551445  \n",
       "1      0.763501      0.787477  \n",
       "2      0.285636      0.307471  \n",
       "3      0.114500      0.118628  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>100</td>\n",
       "      <td>0.602433</td>\n",
       "      <td>0.5953</td>\n",
       "      <td>0.6070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.7876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.905733</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.9075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.966800</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.9673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0      ptyl    100       0.602433        0.5953        0.6070\n",
       "1      ptyl   1000       0.781467        0.7754        0.7876\n",
       "2      ptyl  10000       0.905733        0.9029        0.9075\n",
       "3      ptyl  50000       0.966800        0.9661        0.9673"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>100</td>\n",
       "      <td>1.507246</td>\n",
       "      <td>1.463025</td>\n",
       "      <td>1.551445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.777968</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.787477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.294950</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.307471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.116529</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.118628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0      ptyl    100       1.507246      1.463025      1.551445\n",
       "1      ptyl   1000       0.777968      0.763501      0.787477\n",
       "2      ptyl  10000       0.294950      0.285636      0.307471\n",
       "3      ptyl  50000       0.116529      0.114500      0.118628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>model_name</th>\n",
       "      <th>n</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=235285.22_lr_0=0.001_n=100_random_s...</td>\n",
       "      <td>100</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.164340e+05</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.989701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=235285.22_lr_0=0.001_n=100_random_s...</td>\n",
       "      <td>100</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.470050e+05</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>1.192234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=235285.22_lr_0=0.001_n=100_random_s...</td>\n",
       "      <td>100</td>\n",
       "      <td>3001</td>\n",
       "      <td>4.734726e+05</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.957618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1001</td>\n",
       "      <td>8.184627e+05</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.387852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>7.611993e+05</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.397584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3001</td>\n",
       "      <td>6.584999e+05</td>\n",
       "      <td>0.8709</td>\n",
       "      <td>0.415511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random_...</td>\n",
       "      <td>10000</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.030512e+06</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.255271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random_...</td>\n",
       "      <td>10000</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.195753e+06</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.279246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random_...</td>\n",
       "      <td>10000</td>\n",
       "      <td>3001</td>\n",
       "      <td>3.219495e+06</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.250510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...</td>\n",
       "      <td>50000</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.312191e+06</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.120371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...</td>\n",
       "      <td>50000</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.290469e+06</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.119934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...</td>\n",
       "      <td>50000</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.371019e+06</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.120479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion                                         model_name      n  \\\n",
       "24      ptyl  ptyl_kappa=235285.22_lr_0=0.001_n=100_random_s...    100   \n",
       "25      ptyl  ptyl_kappa=235285.22_lr_0=0.001_n=100_random_s...    100   \n",
       "26      ptyl  ptyl_kappa=235285.22_lr_0=0.001_n=100_random_s...    100   \n",
       "27      ptyl  ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...   1000   \n",
       "28      ptyl  ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...   1000   \n",
       "29      ptyl  ptyl_kappa=23528.522_lr_0=0.001_n=1000_random_...   1000   \n",
       "18      ptyl  ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random_...  10000   \n",
       "19      ptyl  ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random_...  10000   \n",
       "20      ptyl  ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random_...  10000   \n",
       "21      ptyl  ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...  50000   \n",
       "22      ptyl  ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...  50000   \n",
       "23      ptyl  ptyl_kappa=470.57044_lr_0=0.01_n=50000_random_...  50000   \n",
       "\n",
       "    random_state    train_loss  test_acc  test_nll  \n",
       "24          1001  1.164340e+05    0.6974  0.989701  \n",
       "25          2001  8.470050e+05    0.6857  1.192234  \n",
       "26          3001  4.734726e+05    0.7310  0.957618  \n",
       "27          1001  8.184627e+05    0.8753  0.387852  \n",
       "28          2001  7.611993e+05    0.8730  0.397584  \n",
       "29          3001  6.584999e+05    0.8709  0.415511  \n",
       "18          1001  3.030512e+06    0.9501  0.255271  \n",
       "19          2001  3.195753e+06    0.9480  0.279246  \n",
       "20          3001  3.219495e+06    0.9530  0.250510  \n",
       "21          1001  1.312191e+06    0.9672  0.120371  \n",
       "22          2001  1.290469e+06    0.9684  0.119934  \n",
       "23          3001  1.371019e+06    0.9680  0.120479  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = 'ptyl'\n",
    "d = 23528522\n",
    "dataset_directory = '/cluster/tufts/hugheslab/eharve06/CIFAR-10'\n",
    "experiments_directory = '/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_VI'\n",
    "lr_0s = [0.1, 0.01, 0.001, 0.0001]\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "random_states = [1001, 2001, 3001]\n",
    "\n",
    "columns = ['criterion', 'model_name', 'n', 'random_state', 'train_loss', 'test_acc', 'test_nll']\n",
    "retrained_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr_0, n, random_state in itertools.product(lr_0s, ns, random_states):\n",
    "    model_name = f'{criterion}_kappa={d/n}_lr_0={lr_0}_n={n}_random_state={random_state}'\n",
    "    if os.path.exists(f'{experiments_directory}/{model_name}.csv'):\n",
    "        temp_df = pd.read_csv(f'{experiments_directory}/{model_name}.csv')\n",
    "        row = [criterion, model_name, n, random_state, temp_df.train_loss.values[-1], temp_df.val_or_test_acc.values[-1], temp_df.val_or_test_nll.values[-1]]\n",
    "        retrained_df.loc[len(retrained_df)] = row\n",
    "    \n",
    "min_indices = retrained_df.groupby(['criterion', 'n', 'random_state'])['train_loss'].idxmin()\n",
    "retrained_df = retrained_df.loc[min_indices]\n",
    "\n",
    "retrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>model_name</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_std</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>100</td>\n",
       "      <td>(ptyl_kappa=235285.22_lr_0=0.001_n=100_random_...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(116434.0015625, 847005.0390625, 473472.5703125)</td>\n",
       "      <td>(0.6974000334739685, 0.6857000589370728, 0.731...</td>\n",
       "      <td>(0.9897008886337282, 1.1922336833953855, 0.957...</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>1.046517</td>\n",
       "      <td>0.103866</td>\n",
       "      <td>0.957618</td>\n",
       "      <td>1.192234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>1000</td>\n",
       "      <td>(ptyl_kappa=23528.522_lr_0=0.001_n=1000_random...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(818462.7383999999, 761199.2545, 658499.8637)</td>\n",
       "      <td>(0.8753000497817993, 0.8729999661445618, 0.870...</td>\n",
       "      <td>(0.3878521335601806, 0.3975842832326889, 0.415...</td>\n",
       "      <td>0.873067</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.8709</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.400316</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.387852</td>\n",
       "      <td>0.415511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>10000</td>\n",
       "      <td>(ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(3030512.15849, 3195753.482, 3219494.8240875)</td>\n",
       "      <td>(0.9501000642776488, 0.9480000138282776, 0.953...</td>\n",
       "      <td>(0.2552711465358733, 0.2792461663246156, 0.250...</td>\n",
       "      <td>0.950367</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.261676</td>\n",
       "      <td>0.012575</td>\n",
       "      <td>0.250510</td>\n",
       "      <td>0.279246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>50000</td>\n",
       "      <td>(ptyl_kappa=470.57044_lr_0=0.01_n=50000_random...</td>\n",
       "      <td>(1001, 2001, 3001)</td>\n",
       "      <td>(1312191.0982160005, 1290469.4898860003, 13710...</td>\n",
       "      <td>(0.967199981212616, 0.968399941921234, 0.96799...</td>\n",
       "      <td>(0.1203705894708633, 0.119934031355381, 0.1204...</td>\n",
       "      <td>0.967867</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.120261</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.119934</td>\n",
       "      <td>0.120479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n                                         model_name  \\\n",
       "0      ptyl    100  (ptyl_kappa=235285.22_lr_0=0.001_n=100_random_...   \n",
       "1      ptyl   1000  (ptyl_kappa=23528.522_lr_0=0.001_n=1000_random...   \n",
       "2      ptyl  10000  (ptyl_kappa=2352.8522_lr_0=0.01_n=10000_random...   \n",
       "3      ptyl  50000  (ptyl_kappa=470.57044_lr_0=0.01_n=50000_random...   \n",
       "\n",
       "         random_state                                         train_loss  \\\n",
       "0  (1001, 2001, 3001)   (116434.0015625, 847005.0390625, 473472.5703125)   \n",
       "1  (1001, 2001, 3001)      (818462.7383999999, 761199.2545, 658499.8637)   \n",
       "2  (1001, 2001, 3001)      (3030512.15849, 3195753.482, 3219494.8240875)   \n",
       "3  (1001, 2001, 3001)  (1312191.0982160005, 1290469.4898860003, 13710...   \n",
       "\n",
       "                                            test_acc  \\\n",
       "0  (0.6974000334739685, 0.6857000589370728, 0.731...   \n",
       "1  (0.8753000497817993, 0.8729999661445618, 0.870...   \n",
       "2  (0.9501000642776488, 0.9480000138282776, 0.953...   \n",
       "3  (0.967199981212616, 0.968399941921234, 0.96799...   \n",
       "\n",
       "                                            test_nll  test_acc_mean  \\\n",
       "0  (0.9897008886337282, 1.1922336833953855, 0.957...       0.704700   \n",
       "1  (0.3878521335601806, 0.3975842832326889, 0.415...       0.873067   \n",
       "2  (0.2552711465358733, 0.2792461663246156, 0.250...       0.950367   \n",
       "3  (0.1203705894708633, 0.119934031355381, 0.1204...       0.967867   \n",
       "\n",
       "   test_acc_std  test_acc_min  test_acc_max  test_nll_mean  test_nll_std  \\\n",
       "0      0.019200        0.6857        0.7310       1.046517      0.103866   \n",
       "1      0.001797        0.8709        0.8753       0.400316      0.011456   \n",
       "2      0.002050        0.9480        0.9530       0.261676      0.012575   \n",
       "3      0.000499        0.9672        0.9684       0.120261      0.000236   \n",
       "\n",
       "   test_nll_min  test_nll_max  \n",
       "0      0.957618      1.192234  \n",
       "1      0.387852      0.415511  \n",
       "2      0.250510      0.279246  \n",
       "3      0.119934      0.120479  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = retrained_df.groupby(['criterion', 'n']).agg(lambda x: tuple(x))\n",
    "columns = ['test_acc', 'test_nll']\n",
    "for column in columns:\n",
    "    grouped_df[f'{column}_mean'] = grouped_df[column].apply(lambda item: np.mean(item))\n",
    "    grouped_df[f'{column}_std'] = grouped_df[column].apply(lambda item: np.std(item))\n",
    "    grouped_df[f'{column}_min'] = grouped_df[column].apply(lambda item: np.min(item))\n",
    "    grouped_df[f'{column}_max'] = grouped_df[column].apply(lambda item: np.max(item))\n",
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_min</th>\n",
       "      <th>test_acc_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>100</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.873067</td>\n",
       "      <td>0.8709</td>\n",
       "      <td>0.8753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.950367</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.967867</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_acc_mean  test_acc_min  test_acc_max\n",
       "0      ptyl    100       0.704700        0.6857        0.7310\n",
       "1      ptyl   1000       0.873067        0.8709        0.8753\n",
       "2      ptyl  10000       0.950367        0.9480        0.9530\n",
       "3      ptyl  50000       0.967867        0.9672        0.9684"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_acc_mean', 'test_acc_min', 'test_acc_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>n</th>\n",
       "      <th>test_nll_mean</th>\n",
       "      <th>test_nll_min</th>\n",
       "      <th>test_nll_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>100</td>\n",
       "      <td>1.046517</td>\n",
       "      <td>0.957618</td>\n",
       "      <td>1.192234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.400316</td>\n",
       "      <td>0.387852</td>\n",
       "      <td>0.415511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.261676</td>\n",
       "      <td>0.250510</td>\n",
       "      <td>0.279246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptyl</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.120261</td>\n",
       "      <td>0.119934</td>\n",
       "      <td>0.120479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion      n  test_nll_mean  test_nll_min  test_nll_max\n",
       "0      ptyl    100       1.046517      0.957618      1.192234\n",
       "1      ptyl   1000       0.400316      0.387852      0.415511\n",
       "2      ptyl  10000       0.261676      0.250510      0.279246\n",
       "3      ptyl  50000       0.120261      0.119934      0.120479"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df[['criterion', 'n', 'test_nll_mean', 'test_nll_min', 'test_nll_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
