{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "import matplotlib.ticker as ticker\n",
    "# PyTorch\n",
    "import torch\n",
    "# GPyTorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "# BOTorch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def check_epochs(df, n, batch_size=128, steps=6000, drop_last=True):\n",
    "    num_batches = math.floor(n/batch_size) if drop_last else math.ceil(n/batch_size)\n",
    "    epochs = int(steps/num_batches)\n",
    "    return df.shape[0] == epochs\n",
    "\n",
    "def print_job(alpha, beta, dataset, dataset_dir, experiments_dir, lr_0, \n",
    "              method, model, model_arch, n, prior_dir, prior_type, random_state, \n",
    "              save, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        temp_df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "        n_train = n - int((1/5) * n) if tune else n\n",
    "        if check_epochs(temp_df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "            return\n",
    "\n",
    "    command = (\n",
    "        f\"python ../src/main_image_classifiers.py \"\n",
    "        f\"--alpha={alpha} \"\n",
    "        \"--batch_size=128 \"\n",
    "        f\"--beta={beta} \"\n",
    "        f\"--dataset=\\\"{dataset}\\\" \"\n",
    "        f\"--dataset_dir=\\\"{dataset_dir}\\\" \"\n",
    "        f\"--experiments_dir=\\\"{experiments_dir}\\\" \"\n",
    "        f\"--lr_0={lr_0} \"\n",
    "        f\"--method=\\\"{method}\\\" \"\n",
    "        f\"--model=\\\"{model}\\\" \"\n",
    "        f\"--model_arch=\\\"{model_arch}\\\" \"\n",
    "        f\"--model_name=\\\"{model_name}\\\" \"\n",
    "        f\"--n={n} \"\n",
    "        \"--num_workers=0 \"\n",
    "        f\"--prior_dir=\\\"{prior_dir}\\\" \"\n",
    "        f\"--prior_type=\\\"{prior_type}\\\" \"\n",
    "        f\"--random_state={random_state} \"\n",
    "        f\"{'--save' if save else ''}\"\n",
    "        f\"{'--tune' if tune else ''}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"    '{command}'\")\n",
    "    \n",
    "def get_runtime(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"train_sec/epoch\"].sum()\n",
    "\n",
    "def get_val_or_test_acc(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_acc\"].values[-1]\n",
    "    \n",
    "def get_val_or_test_nll(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return float(\"inf\")\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(128, n_train), steps=6000, drop_last=True):\n",
    "        return float(\"inf\")\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_nll\"].values[-1]\n",
    "\n",
    "def get_candidate(train_X, train_Y, seed):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    gp = SingleTaskGP(\n",
    "        train_X=train_X,\n",
    "        train_Y=train_Y,\n",
    "        input_transform=Normalize(d=3),\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    logEI = LogExpectedImprovement(model=gp, best_f=train_Y.max())\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(3), torch.ones(3)]).to(torch.double)\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "      logEI, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    )\n",
    "    \n",
    "    return candidate.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE:\n",
    "\n",
    "# CIFAR-10 n_iters = 41 tuned\n",
    "# Flower-102 n_iters = 41 tuned\n",
    "# Pet-37 n_iters = 41 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 35 retrained\n",
    "# Flower-102 n_iters = 35 retrained\n",
    "# Pet-37 n_iters = 35 retrained\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# CIFAR-10 n_iters = 42 tuned\n",
    "# Flower-102 n_iters = 42 tuned\n",
    "# Pet-37 n_iters = 42 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 36 retrained\n",
    "# Flower-102 n_iters = 36 retrained\n",
    "# Pet-37 n_iters = 36 retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=100_random_state=1001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=100_random_state=1001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=100_random_state=1001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=100_random_state=1001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=100_random_state=1001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=100_random_state=2001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=100_random_state=2001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=100_random_state=2001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=100_random_state=2001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=100_random_state=2001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=100_random_state=3001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=100_random_state=3001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=100_random_state=3001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=100_random_state=3001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=100_random_state=3001' --n=100 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=1000_random_state=1001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=1000_random_state=1001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=1000_random_state=1001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=1000_random_state=1001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=1000_random_state=1001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=1000_random_state=2001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=1000_random_state=2001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=1000_random_state=2001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=1000_random_state=2001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=1000_random_state=2001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=1000_random_state=3001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=1000_random_state=3001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=1000_random_state=3001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=1000_random_state=3001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=1000_random_state=3001' --n=1000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=10000_random_state=1001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=10000_random_state=1001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=10000_random_state=1001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=10000_random_state=1001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=10000_random_state=1001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=10000_random_state=2001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=10000_random_state=2001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=10000_random_state=2001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=10000_random_state=2001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=10000_random_state=2001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=10000_random_state=3001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=10000_random_state=3001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=10000_random_state=3001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=10000_random_state=3001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=10000_random_state=3001' --n=10000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=50000_random_state=1001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=50000_random_state=1001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=50000_random_state=1001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=50000_random_state=1001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=50000_random_state=1001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=1001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=50000_random_state=2001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=50000_random_state=2001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=50000_random_state=2001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=50000_random_state=2001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=50000_random_state=2001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=2001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.00758947976208385 --batch_size=128 --beta=0.0006780776932355295 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0023886297077207034' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.00758947976208385_beta=0.0006780776932355295_lr_0=0.0023886297077207034_n=50000_random_state=3001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.7547413041177135e-06 --batch_size=128 --beta=7.91075667332751e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0005043796336040412' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.7547413041177135e-06_beta=7.91075667332751e-06_lr_0=0.0005043796336040412_n=50000_random_state=3001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=0.004679965619116805 --batch_size=128 --beta=2.4415231675522605e-06 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.01337376014945696' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=0.004679965619116805_beta=2.4415231675522605e-06_lr_0=0.01337376014945696_n=50000_random_state=3001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=1.3690924723771312e-06 --batch_size=128 --beta=1.4026874356562238e-05 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.020832665132000876' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=1.3690924723771312e-06_beta=1.4026874356562238e-05_lr_0=0.020832665132000876_n=50000_random_state=3001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n",
      "    'python ../src/main_image_classifiers.py --alpha=8.099114510269596e-05 --batch_size=128 --beta=0.0008445374360730293 --dataset='CIFAR-10' --dataset_dir='/cluster/tufts/hugheslab/eharve06/CIFAR-10' --experiments_dir='/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/AAA' --lr_0='0.0001488233620888951' --method='MAP' --model='l2-sp' --model_arch='ConvNeXt-Tiny' --model_name='l2-sp_alpha=8.099114510269596e-05_beta=0.0008445374360730293_lr_0=0.0001488233620888951_n=50000_random_state=3001' --n=50000 --num_workers=0 --prior_dir='/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision' --prior_type='convnext_tiny_torchvision' --random_state=3001 --tune'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3291.860970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>1.007312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3343.366074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>1.109125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3278.860939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.700389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3272.871380</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.719501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3273.628606</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>1.173087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3230.555144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>1.062701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3268.283947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>1.086542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3291.831187</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>0.686987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3281.111440</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.768214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3243.486655</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>1.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3227.092121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.800972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3277.909820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.7198</td>\n",
       "      <td>0.855045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3280.359635</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>0.629665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3284.575875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.746152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3549.037177</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.832363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4454.046647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.285629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4524.611128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.296637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4063.706904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>0.228461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4022.136800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.332857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3984.747895</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.609987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4016.258930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.335992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4072.008259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.346304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4051.305701</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.245877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4054.838413</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9318</td>\n",
       "      <td>0.344335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4048.721572</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.587754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4060.639289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.291316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4065.450992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.312051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4084.173862</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.226746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4088.336289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.349956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4095.279586</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.489326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4029.253124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.123259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4002.060090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.178007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4364.201979</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.121723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4020.350709</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.147332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4429.839653</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.514278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4497.965452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.130786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3955.231326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.194294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3991.185536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.126972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3987.344481</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.156141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4015.133413</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.469777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4010.250434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.122698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4034.947552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.188507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3941.649433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.127740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>4014.743275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.149608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3934.732307</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>0.443764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3950.777821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.089069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3941.413181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.167914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3951.336545</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.070494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3973.767057</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3950.686119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.520834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3972.381472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4324.598058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4386.093326</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.071085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4439.871236</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.076352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3896.288365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.479826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3929.935212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.089011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3943.197468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.180698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3967.746135</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.068287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3968.420301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.072847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>3986.666440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.441352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0        n  n_iter  random_state      runtime  \\\n",
       "0   0.007589  0.000678  0.002389    100.0     0.0        1001.0  3291.860970   \n",
       "1   0.000002  0.000008  0.000504    100.0     0.0        1001.0  3343.366074   \n",
       "2   0.004680  0.000002  0.013374    100.0     0.0        1001.0  3278.860939   \n",
       "3   0.000001  0.000014  0.020833    100.0     0.0        1001.0  3272.871380   \n",
       "4   0.000081  0.000845  0.000149    100.0     0.0        1001.0  3273.628606   \n",
       "5   0.007589  0.000678  0.002389    100.0     0.0        2001.0  3230.555144   \n",
       "6   0.000002  0.000008  0.000504    100.0     0.0        2001.0  3268.283947   \n",
       "7   0.004680  0.000002  0.013374    100.0     0.0        2001.0  3291.831187   \n",
       "8   0.000001  0.000014  0.020833    100.0     0.0        2001.0  3281.111440   \n",
       "9   0.000081  0.000845  0.000149    100.0     0.0        2001.0  3243.486655   \n",
       "10  0.007589  0.000678  0.002389    100.0     0.0        3001.0  3227.092121   \n",
       "11  0.000002  0.000008  0.000504    100.0     0.0        3001.0  3277.909820   \n",
       "12  0.004680  0.000002  0.013374    100.0     0.0        3001.0  3280.359635   \n",
       "13  0.000001  0.000014  0.020833    100.0     0.0        3001.0  3284.575875   \n",
       "14  0.000081  0.000845  0.000149    100.0     0.0        3001.0  3549.037177   \n",
       "15  0.007589  0.000678  0.002389   1000.0     0.0        1001.0  4454.046647   \n",
       "16  0.000002  0.000008  0.000504   1000.0     0.0        1001.0  4524.611128   \n",
       "17  0.004680  0.000002  0.013374   1000.0     0.0        1001.0  4063.706904   \n",
       "18  0.000001  0.000014  0.020833   1000.0     0.0        1001.0  4022.136800   \n",
       "19  0.000081  0.000845  0.000149   1000.0     0.0        1001.0  3984.747895   \n",
       "20  0.007589  0.000678  0.002389   1000.0     0.0        2001.0  4016.258930   \n",
       "21  0.000002  0.000008  0.000504   1000.0     0.0        2001.0  4072.008259   \n",
       "22  0.004680  0.000002  0.013374   1000.0     0.0        2001.0  4051.305701   \n",
       "23  0.000001  0.000014  0.020833   1000.0     0.0        2001.0  4054.838413   \n",
       "24  0.000081  0.000845  0.000149   1000.0     0.0        2001.0  4048.721572   \n",
       "25  0.007589  0.000678  0.002389   1000.0     0.0        3001.0  4060.639289   \n",
       "26  0.000002  0.000008  0.000504   1000.0     0.0        3001.0  4065.450992   \n",
       "27  0.004680  0.000002  0.013374   1000.0     0.0        3001.0  4084.173862   \n",
       "28  0.000001  0.000014  0.020833   1000.0     0.0        3001.0  4088.336289   \n",
       "29  0.000081  0.000845  0.000149   1000.0     0.0        3001.0  4095.279586   \n",
       "30  0.007589  0.000678  0.002389  10000.0     0.0        1001.0  4029.253124   \n",
       "31  0.000002  0.000008  0.000504  10000.0     0.0        1001.0  4002.060090   \n",
       "32  0.004680  0.000002  0.013374  10000.0     0.0        1001.0  4364.201979   \n",
       "33  0.000001  0.000014  0.020833  10000.0     0.0        1001.0  4020.350709   \n",
       "34  0.000081  0.000845  0.000149  10000.0     0.0        1001.0  4429.839653   \n",
       "35  0.007589  0.000678  0.002389  10000.0     0.0        2001.0  4497.965452   \n",
       "36  0.000002  0.000008  0.000504  10000.0     0.0        2001.0  3955.231326   \n",
       "37  0.004680  0.000002  0.013374  10000.0     0.0        2001.0  3991.185536   \n",
       "38  0.000001  0.000014  0.020833  10000.0     0.0        2001.0  3987.344481   \n",
       "39  0.000081  0.000845  0.000149  10000.0     0.0        2001.0  4015.133413   \n",
       "40  0.007589  0.000678  0.002389  10000.0     0.0        3001.0  4010.250434   \n",
       "41  0.000002  0.000008  0.000504  10000.0     0.0        3001.0  4034.947552   \n",
       "42  0.004680  0.000002  0.013374  10000.0     0.0        3001.0  3941.649433   \n",
       "43  0.000001  0.000014  0.020833  10000.0     0.0        3001.0  4014.743275   \n",
       "44  0.000081  0.000845  0.000149  10000.0     0.0        3001.0  3934.732307   \n",
       "45  0.007589  0.000678  0.002389  50000.0     0.0        1001.0  3950.777821   \n",
       "46  0.000002  0.000008  0.000504  50000.0     0.0        1001.0  3941.413181   \n",
       "47  0.004680  0.000002  0.013374  50000.0     0.0        1001.0  3951.336545   \n",
       "48  0.000001  0.000014  0.020833  50000.0     0.0        1001.0  3973.767057   \n",
       "49  0.000081  0.000845  0.000149  50000.0     0.0        1001.0  3950.686119   \n",
       "50  0.007589  0.000678  0.002389  50000.0     0.0        2001.0  3972.381472   \n",
       "51  0.000002  0.000008  0.000504  50000.0     0.0        2001.0  4324.598058   \n",
       "52  0.004680  0.000002  0.013374  50000.0     0.0        2001.0  4386.093326   \n",
       "53  0.000001  0.000014  0.020833  50000.0     0.0        2001.0  4439.871236   \n",
       "54  0.000081  0.000845  0.000149  50000.0     0.0        2001.0  3896.288365   \n",
       "55  0.007589  0.000678  0.002389  50000.0     0.0        3001.0  3929.935212   \n",
       "56  0.000002  0.000008  0.000504  50000.0     0.0        3001.0  3943.197468   \n",
       "57  0.004680  0.000002  0.013374  50000.0     0.0        3001.0  3967.746135   \n",
       "58  0.000001  0.000014  0.020833  50000.0     0.0        3001.0  3968.420301   \n",
       "59  0.000081  0.000845  0.000149  50000.0     0.0        3001.0  3986.666440   \n",
       "\n",
       "    seed  val_acc  val_nll  test_acc  test_nll  \n",
       "0    0.0      0.0      inf    0.6895  1.007312  \n",
       "1    1.0      0.0      inf    0.6395  1.109125  \n",
       "2    2.0      0.0      inf    0.7951  0.700389  \n",
       "3    3.0      0.0      inf    0.8095  0.719501  \n",
       "4    4.0      0.0      inf    0.6080  1.173087  \n",
       "5    0.0      0.0      inf    0.7090  1.062701  \n",
       "6    1.0      0.0      inf    0.6696  1.086542  \n",
       "7    2.0      0.0      inf    0.8064  0.686987  \n",
       "8    3.0      0.0      inf    0.8151  0.768214  \n",
       "9    4.0      0.0      inf    0.6548  1.003984  \n",
       "10   0.0      0.0      inf    0.7583  0.800972  \n",
       "11   1.0      0.0      inf    0.7198  0.855045  \n",
       "12   2.0      0.0      inf    0.8176  0.629665  \n",
       "13   3.0      0.0      inf    0.8167  0.746152  \n",
       "14   4.0      0.0      inf    0.7173  0.832363  \n",
       "15   0.0      0.0      inf    0.9226  0.285629  \n",
       "16   1.0      0.0      inf    0.9022  0.296637  \n",
       "17   2.0      0.0      inf    0.9433  0.228461  \n",
       "18   3.0      0.0      inf    0.9335  0.332857  \n",
       "19   4.0      0.0      inf    0.8383  0.609987  \n",
       "20   0.0      0.0      inf    0.9180  0.335992  \n",
       "21   1.0      0.0      inf    0.8851  0.346304  \n",
       "22   2.0      0.0      inf    0.9413  0.245877  \n",
       "23   3.0      0.0      inf    0.9318  0.344335  \n",
       "24   4.0      0.0      inf    0.8432  0.587754  \n",
       "25   0.0      0.0      inf    0.9242  0.291316  \n",
       "26   1.0      0.0      inf    0.8997  0.312051  \n",
       "27   2.0      0.0      inf    0.9437  0.226746  \n",
       "28   3.0      0.0      inf    0.9324  0.349956  \n",
       "29   4.0      0.0      inf    0.8674  0.489326  \n",
       "30   0.0      0.0      inf    0.9671  0.123259  \n",
       "31   1.0      0.0      inf    0.9484  0.178007  \n",
       "32   2.0      0.0      inf    0.9699  0.121723  \n",
       "33   3.0      0.0      inf    0.9700  0.147332  \n",
       "34   4.0      0.0      inf    0.8858  0.514278  \n",
       "35   0.0      0.0      inf    0.9619  0.130786  \n",
       "36   1.0      0.0      inf    0.9421  0.194294  \n",
       "37   2.0      0.0      inf    0.9701  0.126972  \n",
       "38   3.0      0.0      inf    0.9689  0.156141  \n",
       "39   4.0      0.0      inf    0.8895  0.469777  \n",
       "40   0.0      0.0      inf    0.9636  0.122698  \n",
       "41   1.0      0.0      inf    0.9429  0.188507  \n",
       "42   2.0      0.0      inf    0.9691  0.127740  \n",
       "43   3.0      0.0      inf    0.9694  0.149608  \n",
       "44   4.0      0.0      inf    0.8923  0.443764  \n",
       "45   0.0      0.0      inf    0.9719  0.089069  \n",
       "46   1.0      0.0      inf    0.9510  0.167914  \n",
       "47   2.0      0.0      inf    0.9790  0.070494  \n",
       "48   3.0      0.0      inf    0.9821  0.073079  \n",
       "49   4.0      0.0      inf    0.8859  0.520834  \n",
       "50   0.0      0.0      inf    0.9697  0.093000  \n",
       "51   1.0      0.0      inf    0.9468  0.182574  \n",
       "52   2.0      0.0      inf    0.9795  0.071085  \n",
       "53   3.0      0.0      inf    0.9809  0.076352  \n",
       "54   4.0      0.0      inf    0.8895  0.479826  \n",
       "55   0.0      0.0      inf    0.9709  0.089011  \n",
       "56   1.0      0.0      inf    0.9456  0.180698  \n",
       "57   2.0      0.0      inf    0.9795  0.068287  \n",
       "58   3.0      0.0      inf    0.9809  0.072847  \n",
       "59   4.0      0.0      inf    0.8957  0.441352  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"CIFAR-10\"\n",
    "dataset_dir = \"/cluster/tufts/hugheslab/eharve06/CIFAR-10\"\n",
    "model = \"l2-sp\"\n",
    "method = \"MAP\"\n",
    "model_arch = \"ConvNeXt-Tiny\"\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "prior_dir = \"/cluster/tufts/hugheslab/eharve06/convnext_tiny_torchvision\"\n",
    "prior_type = \"convnext_tiny_torchvision\"\n",
    "random_states = [1001, 2001, 3001]\n",
    "retrained_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_ConvNeXt-Tiny_BO\"\n",
    "tuned_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/tuned_CIFAR-10_ConvNeXt-Tiny_BO\"\n",
    "\n",
    "n_iters = 0\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "bounds = torch.tensor([[-6, -6, -4], [-2, -2, -1]], dtype=torch.double)\n",
    "\n",
    "columns = [\"alpha\", \"beta\", \"lr_0\", \"n\", \"n_iter\", \"random_state\", \"runtime\", \"seed\", \"val_acc\", \"val_nll\", \"test_acc\", \"test_nll\"]\n",
    "cifar10_bo_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for n, random_state, seed in itertools.product(ns, random_states, seeds):\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "\n",
    "    train_X = torch.rand(size=(1, 3,), generator=gen, dtype=torch.double)\n",
    "    train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "    \n",
    "    alpha, beta, lr_0 = 10**train_X_bounded[0]\n",
    "    print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "    train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "    \n",
    "    alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "    print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "    \n",
    "    runtime = 0.0\n",
    "    runtime = get_runtime(alpha, beta, tuned_experiments_dir, model, lr_0, n, random_state, True)\n",
    "    runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    \n",
    "    val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "    row = [alpha.item(), beta.item(), lr_0.item(), n, 0, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "    cifar10_bo_df.loc[len(cifar10_bo_df)] = row\n",
    "    \n",
    "    for i in range(1, n_iters+1):\n",
    "\n",
    "        candidate = get_candidate(train_X, train_Y, seed)\n",
    "        candidate_bounded = (bounds[1] - bounds[0]) * candidate + bounds[0]\n",
    "        train_X = torch.cat([train_X, candidate])\n",
    "        train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "                \n",
    "        alpha, beta, lr_0 = 10**candidate_bounded[0]        \n",
    "        print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "        train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "\n",
    "        alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "        #print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "        \n",
    "        runtime = 0.0\n",
    "        runtime = sum([get_runtime(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True) for x in train_X_bounded])\n",
    "        runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        \n",
    "        val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "        row = [alpha.item(), beta.item(), lr_0.item(), n, i, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "        cifar10_bo_df.loc[len(cifar10_bo_df)] = row\n",
    "\n",
    "cifar10_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>3291.860970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.291354</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>1.007312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>9627.154016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3.193286</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>1.007312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>12253.339415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.114461</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.101206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14865.472126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.209142</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.101206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>17441.893066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.216636</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>1.101206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>67689.889091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.029704</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.775284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>70440.697596</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.008025</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.775284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.045352</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>73163.069124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.691157</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.775284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>75813.926749</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.009623</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.775284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>78338.493823</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.168921</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.775284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0      n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389  100.0     0.0        1001.0   3291.860970   \n",
       "1   0.000001  0.000001  0.100000  100.0     1.0        1001.0   9627.154016   \n",
       "2   0.004565  0.001518  0.000627  100.0     2.0        1001.0  12253.339415   \n",
       "3   0.000287  0.010000  0.002248  100.0     3.0        1001.0  14865.472126   \n",
       "4   0.010000  0.010000  0.000100  100.0     4.0        1001.0  17441.893066   \n",
       "..       ...       ...       ...    ...     ...           ...           ...   \n",
       "95  0.000187  0.000001  0.000223  100.0    23.0        1001.0  67689.889091   \n",
       "96  0.000006  0.000001  0.000445  100.0    24.0        1001.0  70440.697596   \n",
       "97  0.000281  0.000030  0.045352  100.0    25.0        1001.0  73163.069124   \n",
       "98  0.000088  0.000769  0.000430  100.0    26.0        1001.0  75813.926749   \n",
       "99  0.000001  0.002566  0.000603  100.0    27.0        1001.0  78338.493823   \n",
       "\n",
       "    seed  val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0     0.60  1.291354    0.6895  1.007312  \n",
       "1    0.0     0.40  3.193286    0.6895  1.007312  \n",
       "2    0.0     0.70  1.114461    0.6500  1.101206  \n",
       "3    0.0     0.60  1.209142    0.6500  1.101206  \n",
       "4    0.0     0.65  1.216636    0.6500  1.101206  \n",
       "..   ...      ...       ...       ...       ...  \n",
       "95   2.0     0.75  1.029704    0.8047  0.775284  \n",
       "96   2.0     0.75  1.008025    0.8047  0.775284  \n",
       "97   2.0     0.80  0.691157    0.8047  0.775284  \n",
       "98   2.0     0.70  1.009623    0.8047  0.775284  \n",
       "99   2.0     0.70  1.168921    0.8047  0.775284  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cifar10_bo_df.to_csv(\"CIFAR-10_ConvNeXt-Tiny_BO.csv\", index=False)\n",
    "cifar10_bo_df = pd.read_csv(\"CIFAR-10_ConvNeXt-Tiny_BO.csv\")\n",
    "cifar10_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE:\n",
    "\n",
    "# CIFAR-10 n_iters = 6 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 5 retrained\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# CIFAR-10 n_iters = 7 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 6 retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>6750.569728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.664725</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>17262.992587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.772601</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22437.080971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.795896</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>27527.874768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.683694</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>32718.751672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.790889</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>57334.673697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.190884</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.231481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7827.780382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.138502</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.219226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22980.140682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.109862</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.265885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>30612.602440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.216755</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.265885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>38181.246290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.370946</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.265885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0       n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389   100.0     0.0        1001.0   6750.569728   \n",
       "1   0.000001  0.000001  0.100000   100.0     1.0        1001.0  17262.992587   \n",
       "2   0.001950  0.001412  0.000690   100.0     2.0        1001.0  22437.080971   \n",
       "3   0.010000  0.007690  0.040400   100.0     3.0        1001.0  27527.874768   \n",
       "4   0.010000  0.000087  0.000550   100.0     4.0        1001.0  32718.751672   \n",
       "..       ...       ...       ...     ...     ...           ...           ...   \n",
       "95  0.010000  0.000001  0.000100  1000.0     5.0        1001.0  57334.673697   \n",
       "96  0.000002  0.000008  0.000504  1000.0     0.0        1001.0   7827.780382   \n",
       "97  0.003442  0.010000  0.064100  1000.0     1.0        1001.0  22980.140682   \n",
       "98  0.008463  0.005513  0.010742  1000.0     2.0        1001.0  30612.602440   \n",
       "99  0.000390  0.010000  0.100000  1000.0     3.0        1001.0  38181.246290   \n",
       "\n",
       "    seed  val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0    0.750  0.664725    0.8786  0.382506  \n",
       "1    0.0    0.500  2.772601    0.8786  0.382506  \n",
       "2    0.0    0.700  0.795896    0.8786  0.382506  \n",
       "3    0.0    0.500  1.683694    0.8786  0.382506  \n",
       "4    0.0    0.700  0.790889    0.8786  0.382506  \n",
       "..   ...      ...       ...       ...       ...  \n",
       "95   0.0    0.960  0.190884    0.9373  0.231481  \n",
       "96   1.0    0.950  0.138502    0.9375  0.219226  \n",
       "97   1.0    0.960  0.109862    0.9300  0.265885  \n",
       "98   1.0    0.940  0.216755    0.9300  0.265885  \n",
       "99   1.0    0.915  0.370946    0.9300  0.265885  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"CIFAR-10\"\n",
    "dataset_dir = \"/cluster/tufts/hugheslab/eharve06/CIFAR-10\"\n",
    "model = \"l2-sp\"\n",
    "method = \"MAP\"\n",
    "model_arch = \"ViT-B/16\"\n",
    "ns = [100, 1000, 10000, 50000]\n",
    "prior_dir = \"/cluster/tufts/hugheslab/eharve06/vit_b_16_torchvision\"\n",
    "prior_type = \"vit_b_16_torchvision\"\n",
    "random_states = [1001, 2001, 3001]\n",
    "retrained_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_ViT_B_16_BO\"\n",
    "tuned_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/tuned_CIFAR-10_ViT_B_16_BO\"\n",
    "\n",
    "n_iters = 5\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "bounds = torch.tensor([[-6, -6, -4], [-2, -2, -1]], dtype=torch.double)\n",
    "\n",
    "columns = [\"alpha\", \"beta\", \"lr_0\", \"n\", \"n_iter\", \"random_state\", \"runtime\", \"seed\", \"val_acc\", \"val_nll\", \"test_acc\", \"test_nll\"]\n",
    "cifar10_bo_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for n, random_state, seed in itertools.product(ns, random_states, seeds):\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "\n",
    "    train_X = torch.rand(size=(1, 3,), generator=gen, dtype=torch.double)\n",
    "    train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "    \n",
    "    alpha, beta, lr_0 = 10**train_X_bounded[0]\n",
    "    print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "    train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "    \n",
    "    alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "    print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "    \n",
    "    runtime = 0.0\n",
    "    runtime = get_runtime(alpha, beta, tuned_experiments_dir, model, lr_0, n, random_state, True)\n",
    "    runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    \n",
    "    val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "    row = [alpha.item(), beta.item(), lr_0.item(), n, 0, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "    cifar10_bo_df.loc[len(cifar10_bo_df)] = row\n",
    "    \n",
    "    for i in range(1, n_iters+1):\n",
    "\n",
    "        candidate = get_candidate(train_X, train_Y, seed)\n",
    "        candidate_bounded = (bounds[1] - bounds[0]) * candidate + bounds[0]\n",
    "        train_X = torch.cat([train_X, candidate])\n",
    "        train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "                \n",
    "        alpha, beta, lr_0 = 10**candidate_bounded[0]        \n",
    "        print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "        train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "\n",
    "        alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "        #print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "        \n",
    "        runtime = 0.0\n",
    "        runtime = sum([get_runtime(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True) for x in train_X_bounded])\n",
    "        runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        \n",
    "        val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "        row = [alpha.item(), beta.item(), lr_0.item(), n, i, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "        cifar10_bo_df.loc[len(cifar10_bo_df)] = row\n",
    "\n",
    "cifar10_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>6750.569728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.664725</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>17262.992587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.772601</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22437.080971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.795896</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>27527.874768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.683694</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>32718.751672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.790889</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.382506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>57334.673697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.190884</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.231481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7827.780382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.138502</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.219226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22980.140682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.109862</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.265885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>30612.602440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.216755</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.265885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>38181.246290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.370946</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.265885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0       n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389   100.0     0.0        1001.0   6750.569728   \n",
       "1   0.000001  0.000001  0.100000   100.0     1.0        1001.0  17262.992587   \n",
       "2   0.001950  0.001412  0.000690   100.0     2.0        1001.0  22437.080971   \n",
       "3   0.010000  0.007690  0.040400   100.0     3.0        1001.0  27527.874768   \n",
       "4   0.010000  0.000087  0.000550   100.0     4.0        1001.0  32718.751672   \n",
       "..       ...       ...       ...     ...     ...           ...           ...   \n",
       "95  0.010000  0.000001  0.000100  1000.0     5.0        1001.0  57334.673697   \n",
       "96  0.000002  0.000008  0.000504  1000.0     0.0        1001.0   7827.780382   \n",
       "97  0.003442  0.010000  0.064100  1000.0     1.0        1001.0  22980.140682   \n",
       "98  0.008463  0.005513  0.010742  1000.0     2.0        1001.0  30612.602440   \n",
       "99  0.000390  0.010000  0.100000  1000.0     3.0        1001.0  38181.246290   \n",
       "\n",
       "    seed  val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0    0.750  0.664725    0.8786  0.382506  \n",
       "1    0.0    0.500  2.772601    0.8786  0.382506  \n",
       "2    0.0    0.700  0.795896    0.8786  0.382506  \n",
       "3    0.0    0.500  1.683694    0.8786  0.382506  \n",
       "4    0.0    0.700  0.790889    0.8786  0.382506  \n",
       "..   ...      ...       ...       ...       ...  \n",
       "95   0.0    0.960  0.190884    0.9373  0.231481  \n",
       "96   1.0    0.950  0.138502    0.9375  0.219226  \n",
       "97   1.0    0.960  0.109862    0.9300  0.265885  \n",
       "98   1.0    0.940  0.216755    0.9300  0.265885  \n",
       "99   1.0    0.915  0.370946    0.9300  0.265885  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cifar10_bo_df.to_csv(\"CIFAR-10_ViT_B_16_BO.csv\", index=False)\n",
    "cifar10_bo_df = pd.read_csv(\"CIFAR-10_ViT_B_16_BO.csv\")\n",
    "cifar10_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE:\n",
    "\n",
    "# CIFAR-10 n_iters = 11 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 11 retrained\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# CIFAR-10 n_iters = 12 tuned\n",
    "\n",
    "# CIFAR-10 n_iters = 12 retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2079.274698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.246327</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.214758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>6055.884249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.359137</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.214758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7919.535531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.224003</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.217172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>9832.100755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.220109</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.210503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>11791.489255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.836178</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.210503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>26379.588150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.210918</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.178149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2018.297087</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.249594</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.239866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>6174.177397</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.845951</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.239866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>8248.324189</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>0.237979</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.244793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>10182.014808</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.234429</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.213595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0        n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389  10000.0     0.0        1001.0   2079.274698   \n",
       "1   0.000001  0.000001  0.100000  10000.0     1.0        1001.0   6055.884249   \n",
       "2   0.002775  0.001468  0.000655  10000.0     2.0        1001.0   7919.535531   \n",
       "3   0.000138  0.010000  0.000741  10000.0     3.0        1001.0   9832.100755   \n",
       "4   0.010000  0.010000  0.000100  10000.0     4.0        1001.0  11791.489255   \n",
       "..       ...       ...       ...      ...     ...           ...           ...   \n",
       "95  0.000001  0.010000  0.009679  10000.0    11.0        2001.0  26379.588150   \n",
       "96  0.000001  0.000014  0.020833  10000.0     0.0        2001.0   2018.297087   \n",
       "97  0.004370  0.010000  0.000100  10000.0     1.0        2001.0   6174.177397   \n",
       "98  0.000001  0.000001  0.012291  10000.0     2.0        2001.0   8248.324189   \n",
       "99  0.000001  0.001457  0.000636  10000.0     3.0        2001.0  10182.014808   \n",
       "\n",
       "    seed  val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0   0.9320  0.246327    0.9392  0.214758  \n",
       "1    0.0   0.9300  0.359137    0.9392  0.214758  \n",
       "2    0.0   0.9195  0.224003    0.9283  0.217172  \n",
       "3    0.0   0.9210  0.220109    0.9309  0.210503  \n",
       "4    0.0   0.8090  0.836178    0.9309  0.210503  \n",
       "..   ...      ...       ...       ...       ...  \n",
       "95   2.0   0.9365  0.210918    0.9506  0.178149  \n",
       "96   3.0   0.9465  0.249594    0.9508  0.239866  \n",
       "97   3.0   0.8005  0.845951    0.9508  0.239866  \n",
       "98   3.0   0.9430  0.237979    0.9479  0.244793  \n",
       "99   3.0   0.9235  0.234429    0.9304  0.213595  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"CIFAR-10\"\n",
    "dataset_dir = \"/cluster/tufts/hugheslab/eharve06/CIFAR-10\"\n",
    "model = \"l2-sp\"\n",
    "method = \"MAP\"\n",
    "model_arch = \"ResNet-50\"\n",
    "ns = [10000, 50000]\n",
    "prior_dir = \"/cluster/tufts/hugheslab/eharve06/resnet50_torchvision\"\n",
    "prior_type = \"resnet50_torchvision\"\n",
    "random_states = [1001, 2001, 3001]\n",
    "retrained_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_CIFAR-10_BO\"\n",
    "tuned_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/tuned_CIFAR-10_BO\"\n",
    "\n",
    "n_iters = 11\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "bounds = torch.tensor([[-6, -6, -4], [-2, -2, -1]], dtype=torch.double)\n",
    "\n",
    "columns = [\"alpha\", \"beta\", \"lr_0\", \"n\", \"n_iter\", \"random_state\", \"runtime\", \"seed\", \"val_acc\", \"val_nll\", \"test_acc\", \"test_nll\"]\n",
    "cifar10_bo_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for n, random_state, seed in itertools.product(ns, random_states, seeds):\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "\n",
    "    train_X = torch.rand(size=(1, 3,), generator=gen, dtype=torch.double)\n",
    "    train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "    \n",
    "    alpha, beta, lr_0 = 10**train_X_bounded[0]\n",
    "    print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "    train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "    \n",
    "    alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "    print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "    \n",
    "    runtime = 0.0\n",
    "    runtime = get_runtime(alpha, beta, tuned_experiments_dir, model, lr_0, n, random_state, True)\n",
    "    runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    \n",
    "    val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "    row = [alpha.item(), beta.item(), lr_0.item(), n, 0, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "    cifar10_bo_df.loc[len(cifar10_bo_df)] = row\n",
    "    \n",
    "    for i in range(1, n_iters+1):\n",
    "\n",
    "        candidate = get_candidate(train_X, train_Y, seed)\n",
    "        candidate_bounded = (bounds[1] - bounds[0]) * candidate + bounds[0]\n",
    "        train_X = torch.cat([train_X, candidate])\n",
    "        train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "                \n",
    "        alpha, beta, lr_0 = 10**candidate_bounded[0]        \n",
    "        print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "        train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "\n",
    "        alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "        #print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "        \n",
    "        runtime = 0.0\n",
    "        runtime = sum([get_runtime(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True) for x in train_X_bounded])\n",
    "        runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        \n",
    "        val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "        row = [alpha.item(), beta.item(), lr_0.item(), n, i, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "        cifar10_bo_df.loc[len(cifar10_bo_df)] = row\n",
    "\n",
    "cifar10_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2079.274698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.246327</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.214758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>6055.884249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.359137</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.214758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>7919.535531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.224003</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.217172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>9832.100755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.220109</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.210503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>11791.489255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.836178</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.210503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>26379.588150</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.210918</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.178149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2018.297087</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.249594</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.239866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>6174.177397</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.845951</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.239866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>8248.324189</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>0.237979</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.244793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>10182.014808</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.234429</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.213595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0        n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389  10000.0     0.0        1001.0   2079.274698   \n",
       "1   0.000001  0.000001  0.100000  10000.0     1.0        1001.0   6055.884249   \n",
       "2   0.002775  0.001468  0.000655  10000.0     2.0        1001.0   7919.535531   \n",
       "3   0.000138  0.010000  0.000741  10000.0     3.0        1001.0   9832.100755   \n",
       "4   0.010000  0.010000  0.000100  10000.0     4.0        1001.0  11791.489255   \n",
       "..       ...       ...       ...      ...     ...           ...           ...   \n",
       "95  0.000001  0.010000  0.009679  10000.0    11.0        2001.0  26379.588150   \n",
       "96  0.000001  0.000014  0.020833  10000.0     0.0        2001.0   2018.297087   \n",
       "97  0.004370  0.010000  0.000100  10000.0     1.0        2001.0   6174.177397   \n",
       "98  0.000001  0.000001  0.012291  10000.0     2.0        2001.0   8248.324189   \n",
       "99  0.000001  0.001457  0.000636  10000.0     3.0        2001.0  10182.014808   \n",
       "\n",
       "    seed  val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0   0.9320  0.246327    0.9392  0.214758  \n",
       "1    0.0   0.9300  0.359137    0.9392  0.214758  \n",
       "2    0.0   0.9195  0.224003    0.9283  0.217172  \n",
       "3    0.0   0.9210  0.220109    0.9309  0.210503  \n",
       "4    0.0   0.8090  0.836178    0.9309  0.210503  \n",
       "..   ...      ...       ...       ...       ...  \n",
       "95   2.0   0.9365  0.210918    0.9506  0.178149  \n",
       "96   3.0   0.9465  0.249594    0.9508  0.239866  \n",
       "97   3.0   0.8005  0.845951    0.9508  0.239866  \n",
       "98   3.0   0.9430  0.237979    0.9479  0.244793  \n",
       "99   3.0   0.9235  0.234429    0.9304  0.213595  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cifar10_bo_df.to_csv(\"CIFAR-10_BO.csv\", index=False)\n",
    "cifar10_bo_df = pd.read_csv(\"CIFAR-10_BO.csv\")\n",
    "cifar10_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
