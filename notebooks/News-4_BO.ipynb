{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "import matplotlib.ticker as ticker\n",
    "# PyTorch\n",
    "import torch\n",
    "# GPyTorch\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "# BOTorch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import LogExpectedImprovement\n",
    "from botorch.optim import optimize_acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "def check_epochs(df, n, batch_size=128, steps=6000, drop_last=True):\n",
    "    num_batches = math.floor(n/batch_size) if drop_last else math.ceil(n/batch_size)\n",
    "    epochs = int(steps/num_batches)\n",
    "    return df.shape[0] == epochs\n",
    "\n",
    "def print_job(alpha, beta, dataset, dataset_dir, experiments_dir, lr_0, \n",
    "              method, model, model_arch, n, prior_dir, prior_type, random_state, \n",
    "              save, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        temp_df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "        n_train = n - int((1/5) * n) if tune else n\n",
    "        if check_epochs(temp_df, n_train, batch_size=min(32, n_train), steps=12000, drop_last=False):\n",
    "            return\n",
    "\n",
    "    command = (\n",
    "        f\"python ../src/main_text_classifiers.py \"\n",
    "        f\"--alpha={alpha} \"\n",
    "        \"--batch_size=32 \"\n",
    "        f\"--beta={beta} \"\n",
    "        f\"--dataset=\\\"{dataset}\\\" \"\n",
    "        f\"--dataset_dir=\\\"{dataset_dir}\\\" \"\n",
    "        f\"--experiments_dir=\\\"{experiments_dir}\\\" \"\n",
    "        f\"--lr_0={lr_0} \"\n",
    "        f\"--method=\\\"{method}\\\" \"\n",
    "        f\"--model=\\\"{model}\\\" \"\n",
    "        f\"--model_arch=\\\"{model_arch}\\\" \"\n",
    "        f\"--model_name=\\\"{model_name}\\\" \"\n",
    "        f\"--n={n} \"\n",
    "        \"--num_workers=0 \"\n",
    "        f\"--prior_dir=\\\"{prior_dir}\\\" \"\n",
    "        f\"--prior_type=\\\"{prior_type}\\\" \"\n",
    "        f\"--random_state={random_state} \"\n",
    "        f\"{'--save' if save else ''}\"\n",
    "        f\"{'--tune' if tune else ''}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"    '{command}'\")\n",
    "    \n",
    "def get_runtime(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(32, n_train), steps=12000, drop_last=False):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"train_sec/epoch\"].sum()\n",
    "\n",
    "def get_val_or_test_acc(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return 0.0\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(32, n_train), steps=12000, drop_last=False):\n",
    "        return 0.0\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_acc\"].values[-1]\n",
    "    \n",
    "def get_val_or_test_nll(alpha, beta, experiments_dir, lr_0, model, n, random_state, tune):\n",
    "    model_name = f\"{model}_alpha={alpha}_beta={beta}_lr_0={lr_0}_n={n}_random_state={random_state}\"\n",
    "    if not os.path.exists(f\"{experiments_dir}/{model_name}.csv\"):\n",
    "        return float(\"inf\")\n",
    "        #raise FileNotFoundError(f\"Expected file not found: {experiments_dir}/{model_name}.csv\")\n",
    "    df = pd.read_csv(f\"{experiments_dir}/{model_name}.csv\")\n",
    "    n_train = n - int((1/5) * n) if tune else n\n",
    "    if not check_epochs(df, n_train, batch_size=min(32, n_train), steps=12000, drop_last=False):\n",
    "        return float(\"inf\")\n",
    "        #raise RuntimeError(f\"Run incomplete: {model_name} did not run for the specified number of epochs\")\n",
    "    return df[\"val_or_test_nll\"].values[-1]\n",
    "\n",
    "def get_candidate(train_X, train_Y, seed):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    gp = SingleTaskGP(\n",
    "        train_X=train_X,\n",
    "        train_Y=train_Y,\n",
    "        input_transform=Normalize(d=3),\n",
    "        outcome_transform=Standardize(m=1),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    logEI = LogExpectedImprovement(model=gp, best_f=train_Y.max())\n",
    "\n",
    "    bounds = torch.stack([torch.zeros(3), torch.ones(3)]).to(torch.double)\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "      logEI, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    )\n",
    "    \n",
    "    return candidate.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In queue:\n",
    "\n",
    "# News-4 n_iters = 12 tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE:\n",
    "\n",
    "# News-4 n_iters = 11 tuned\n",
    "\n",
    "# News-4 n_iters = 11 retrained\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# News-4 n_iters = 12 tuned\n",
    "\n",
    "# News-4 n_iters = 12 retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14682.265820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934875</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.020449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22301.092462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.129966</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.020449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>29777.094771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.078326</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>37304.995549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911625</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>44933.403602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>0.025521</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>98403.808607</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.020371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14907.553491</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.912125</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22467.267115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.129970</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>30277.997782</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.905750</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>38011.291657</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0        n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389  40000.0     0.0        1001.0  14682.265820   \n",
       "1   0.000001  0.000001  0.100000  40000.0     1.0        1001.0  22301.092462   \n",
       "2   0.004011  0.001500  0.000631  40000.0     2.0        1001.0  29777.094771   \n",
       "3   0.002254  0.010000  0.078326  40000.0     3.0        1001.0  37304.995549   \n",
       "4   0.004851  0.000001  0.100000  40000.0     4.0        1001.0  44933.403602   \n",
       "..       ...       ...       ...      ...     ...           ...           ...   \n",
       "95  0.000001  0.000001  0.001470  40000.0    11.0        1001.0  98403.808607   \n",
       "96  0.001360  0.000193  0.000214  40000.0     0.0        1001.0  14907.553491   \n",
       "97  0.000001  0.000001  0.100000  40000.0     1.0        1001.0  22467.267115   \n",
       "98  0.002509  0.001321  0.000134  40000.0     2.0        1001.0  30277.997782   \n",
       "99  0.010000  0.000001  0.000100  40000.0     3.0        1001.0  38011.291657   \n",
       "\n",
       "    seed   val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0  0.934875  0.020004  0.932500  0.020449  \n",
       "1    0.0  0.250000  0.129966  0.932500  0.020449  \n",
       "2    0.0  0.927000  0.019971  0.922368  0.021701  \n",
       "3    0.0  0.911625  0.025204  0.922368  0.021701  \n",
       "4    0.0  0.916750  0.025521  0.922368  0.021701  \n",
       "..   ...       ...       ...       ...       ...  \n",
       "95   7.0  0.932750  0.019107  0.930000  0.020371  \n",
       "96   8.0  0.912125  0.023456  0.908684  0.024769  \n",
       "97   8.0  0.250000  0.129970  0.908684  0.024769  \n",
       "98   8.0  0.905750  0.025177  0.908684  0.024769  \n",
       "99   8.0  0.902000  0.026312  0.908684  0.024769  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"News-4\"\n",
    "dataset_dir = \"/cluster/tufts/hugheslab/eharve06/News-4\"\n",
    "model = \"l2-sp\"\n",
    "method = \"MAP\"\n",
    "model_arch = \"BERT-base\"\n",
    "ns = [40000, 120000]\n",
    "prior_dir = \"\"\n",
    "prior_type = \"\"\n",
    "random_states = [1001, 2001, 3001]\n",
    "retrained_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/retrained_News-4_BO\"\n",
    "tuned_experiments_dir = \"/cluster/tufts/hugheslab/eharve06/data-emphasized-ELBo/experiments/tuned_News-4_BO\"\n",
    "\n",
    "n_iters = 11\n",
    "seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "bounds = torch.tensor([[-6, -6, -4], [-2, -2, -1]], dtype=torch.double)\n",
    "\n",
    "columns = [\"alpha\", \"beta\", \"lr_0\", \"n\", \"n_iter\", \"random_state\", \"runtime\", \"seed\", \"val_acc\", \"val_nll\", \"test_acc\", \"test_nll\"]\n",
    "news4_bo_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for n, random_state, seed in itertools.product(ns, random_states, seeds):\n",
    "\n",
    "    gen = torch.Generator()\n",
    "    gen.manual_seed(seed)\n",
    "\n",
    "    train_X = torch.rand(size=(1, 3,), generator=gen, dtype=torch.double)\n",
    "    train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "    \n",
    "    alpha, beta, lr_0 = 10**train_X_bounded[0]\n",
    "    print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "    train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "    \n",
    "    alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "    print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "    \n",
    "    runtime = get_runtime(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    \n",
    "    val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "    test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "    test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "    row = [alpha.item(), beta.item(), lr_0.item(), n, 0, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "    news4_bo_df.loc[len(news4_bo_df)] = row\n",
    "    \n",
    "    for i in range(1, n_iters+1):\n",
    "\n",
    "        candidate = get_candidate(train_X, train_Y, seed)\n",
    "        candidate_bounded = (bounds[1] - bounds[0]) * candidate + bounds[0]\n",
    "        train_X = torch.cat([train_X, candidate])\n",
    "        train_X_bounded = (bounds[1] - bounds[0]) * train_X + bounds[0]\n",
    "                \n",
    "        alpha, beta, lr_0 = 10**candidate_bounded[0]        \n",
    "        print_job(alpha, beta, dataset, dataset_dir, tuned_experiments_dir, lr_0, method, model, model_arch, n, prior_dir, prior_type, random_state, False, True)\n",
    "\n",
    "        train_Y = torch.tensor([[-get_val_or_test_nll(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True)] for x in train_X_bounded], dtype=torch.float64)\n",
    "\n",
    "        alpha_star, beta_star, lr_0_star = 10**train_X_bounded[torch.argmax(train_Y)]\n",
    "        #print_job(alpha_star, beta_star, dataset, dataset_dir, retrained_experiments_dir, lr_0_star, method, model, model_arch, n, prior_dir, prior_type, random_state, True, False)\n",
    "        \n",
    "        runtime = sum([get_runtime(10**x[0], 10**x[1], tuned_experiments_dir, 10**x[2], model, n, random_state, True) for x in train_X_bounded])\n",
    "        runtime += get_runtime(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        \n",
    "        val_acc = get_val_or_test_acc(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        val_nll = get_val_or_test_nll(alpha, beta, tuned_experiments_dir, lr_0, model, n, random_state, True)\n",
    "        test_acc = get_val_or_test_acc(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "        test_nll = get_val_or_test_nll(alpha_star, beta_star, retrained_experiments_dir, lr_0_star, model, n, random_state, False)\n",
    "\n",
    "        row = [alpha.item(), beta.item(), lr_0.item(), n, i, random_state, runtime, seed, val_acc, val_nll, test_acc, test_nll]\n",
    "        news4_bo_df.loc[len(news4_bo_df)] = row\n",
    "\n",
    "news4_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>lr_0</th>\n",
       "      <th>n</th>\n",
       "      <th>n_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seed</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_nll</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_nll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14682.265820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934875</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.020449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22301.092462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.129966</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.020449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>29777.094771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.078326</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>37304.995549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911625</td>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>44933.403602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>0.025521</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>98403.808607</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.020371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>14907.553491</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.912125</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22467.267115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.129970</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>30277.997782</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.905750</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>38011.291657</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.024769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha      beta      lr_0        n  n_iter  random_state       runtime  \\\n",
       "0   0.007589  0.000678  0.002389  40000.0     0.0        1001.0  14682.265820   \n",
       "1   0.000001  0.000001  0.100000  40000.0     1.0        1001.0  22301.092462   \n",
       "2   0.004011  0.001500  0.000631  40000.0     2.0        1001.0  29777.094771   \n",
       "3   0.002254  0.010000  0.078326  40000.0     3.0        1001.0  37304.995549   \n",
       "4   0.004851  0.000001  0.100000  40000.0     4.0        1001.0  44933.403602   \n",
       "..       ...       ...       ...      ...     ...           ...           ...   \n",
       "95  0.000001  0.000001  0.001470  40000.0    11.0        1001.0  98403.808607   \n",
       "96  0.001360  0.000193  0.000214  40000.0     0.0        1001.0  14907.553491   \n",
       "97  0.000001  0.000001  0.100000  40000.0     1.0        1001.0  22467.267115   \n",
       "98  0.002509  0.001321  0.000134  40000.0     2.0        1001.0  30277.997782   \n",
       "99  0.010000  0.000001  0.000100  40000.0     3.0        1001.0  38011.291657   \n",
       "\n",
       "    seed   val_acc   val_nll  test_acc  test_nll  \n",
       "0    0.0  0.934875  0.020004  0.932500  0.020449  \n",
       "1    0.0  0.250000  0.129966  0.932500  0.020449  \n",
       "2    0.0  0.927000  0.019971  0.922368  0.021701  \n",
       "3    0.0  0.911625  0.025204  0.922368  0.021701  \n",
       "4    0.0  0.916750  0.025521  0.922368  0.021701  \n",
       "..   ...       ...       ...       ...       ...  \n",
       "95   7.0  0.932750  0.019107  0.930000  0.020371  \n",
       "96   8.0  0.912125  0.023456  0.908684  0.024769  \n",
       "97   8.0  0.250000  0.129970  0.908684  0.024769  \n",
       "98   8.0  0.905750  0.025177  0.908684  0.024769  \n",
       "99   8.0  0.902000  0.026312  0.908684  0.024769  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#news4_bo_df.to_csv(\"News-4_BERT-base_BO.csv\", index=False)\n",
    "news4_bo_df = pd.read_csv(\"News-4_BERT-base_BO.csv\")\n",
    "news4_bo_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l3d_2024f_cuda12_1",
   "language": "python",
   "name": "l3d_2024f_cuda12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
